---
title: "Analyse des donn√©es comportementales"
subtitle: "M√©moire ‚Äì Master 1 Sciences Cognitives"
author: "<i>M√©lody Hannoah, Marianne Mortier-Mourzelas & Astrid Th√©bault Guiochon</i>"
output: 
  html_document:
    toc: true # table of content true
    toc_depth: 3  # nombre de niveaux
    toc_float: true
      #collapsed: false # montrer tous les niveaux de titre
    # number_sections: true  # num√©roter les titres
    theme: lumen #united (orange mais le gras ne se voit pas)
    highlight: kate #th√®me du code
tags: [knitr, servr]
---

```{r setup, include = FALSE}
options(knitr.kable.NA = '', knitr.table.format = "html")
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

# I -- Chargement

## 1. Librairies

### a) Pr√©cisions

üí° *On installe une seule fois sur son ordi les librairies avec :*

    install.packages("NomDeLaLibrairie")

*On appelle au d√©but du script √† chaque fois avec :*

    library(NomDeLaLibrairie)

### b) Installation

‚ö†Ô∏è N√©cessaire uniquement la premi√®re fois qu'on ex√©cute le script (sauf si on a d√©j√† install√© ces librairies).

üí° *Ajouter CRAN entre les {}*

```{}
    tinytex::install_tinytex()
    install.packages("agricolae") 
    install.packages("car")
    install.packages("corrplot")
    install.packages("dplyr")
    install.packages("expss")
    install.packages("flextable")
    install.packages("ggpubr")
    install.packages("gtsummary")  
    install.packages("Hmisc")
    install.packages("kableExtra")
    install.packages("knitr")
    install.packages("labelled")
    install.packages("lme4")
    install.packages("lmerTest")
    install.packages("lsr")
    install.packages("magrittr")
    install.packages("psy")
    install.packages("psych")
    install.packages("purrr")
    install.packages("RCurl")
    install.packages("skimr")
    install.packages("sjlabelled")
    install.packages("sjPlot")
    install.packages("sjstats")
    install.packages("tidyverse")
```

### c) D√©claration

On d√©clare les librairies qu'on utilise et permettent d'appeler des fonctions particuli√®res.

```{r libraries}
library(agricolae)
library(car)
library(corrplot)
library(dplyr)
library(expss)
library(flextable)
library(ggpubr)
library(gtsummary)  
library(Hmisc)
library(kableExtra)
library(knitr)
library(labelled)
library(lme4)
library(lmerTest)
library(lsr)
library(magrittr)
library(psy)
library(psych)
library(purrr)
library(RCurl)
library(skimr)
library(sjlabelled)
library(sjPlot)
library(sjstats)
library(tidyverse)
```

## 2. R√©pertoire de travail

‚ö†Ô∏è R√©pertoire par d√©faut : MacBook d'As.

üí° *√Ä adapter selon l'user*

```{r directory}
# setwd("/Users/astridguiochon/Library/CloudStorage/OneDrive-Personnel/Documents/M1/S2 SCo/Criminalistique/Analyse/Stats")
```

## 3. Ouverture du fichier

üí° *Si jamais il importe les donn√©es en un gros bloc au lieu d'un tableau, remplacer le sep = ";" par sep = "," (d√©pend de la version d'Excel et comment il exporte en .csv).*

```{r data}
data = read.csv(file = 'https://raw.githubusercontent.com/astridgcn/R-Behavioral-Analysis/main/Comptage.csv', sep = ";", check.names = F, header = TRUE) 
```

## 4. Pr√©paration des donn√©es

Transformation des donn√©es dans les bons formats

```{r factorize}
data$Condition <- factor(data$Condition, labels = c("Agression", "T√©l√©phone") )
data$Sexe <- factor(data$Sexe, 
                    labels = c("F√©minin", "Masculin"))
```

Filtrage des donn√©es vides

```{r filter}
data <- filter(data, data$Total_SM > 0)
```

√âtiquette de noms des donn√©es

```{r labels, include = FALSE}
var_label(data) <- list(Sexe = "Sexe",
                         Condition = "Condition",
                         Haut_visage = "Nombre de mouvements du haut du visage √† l'arr√™t 1",
                         Bas_visage = "Nombre de mouvements du bas du visage √† l'arr√™t 1",
                         Clignements = "Nombre de clignements des yeux √† l'arr√™t 1",
                         Yeux = "Nombre de mouvements des yeux √† l'arr√™t 1",
                         Tete = "Nombre de mouvements de la t√™te √† l'arr√™t 1",
                         Buste = "Nombre de mouvements du buste √† l'arr√™t 1",
                         Bras = "Nombre de mouvements des bras √† l'arr√™t 1",
                         Mains = "Nombre de mouvements des mains √† l'arr√™t 1",
                         Jambes = "Nombre de mouvements des jambes √† l'arr√™t 1",
                         Pieds = "Nombre de mouvements des pieds √† l'arr√™t 1",
                         Self_Adaptators = "Nombre de self-adaptators √† l'arr√™t 1",
                         Pas_P1_P2 = "Nombre de pas entre l'arr√™t 1 et l'arr√™t 2",
                         Temps_P1_P2 = "Temps entre l'arr√™t 1 et l'arr√™t 2 (en secondes)",
                         Vitesse_P1_P2 = "Vitesse entre l'arr√™t 1 et l'arr√™t 2",
                           
                         Haut_visage2 = "Nombre de mouvements du haut du visage √† l'arr√™t 2",
                         Bas_visage2 = "Nombre de mouvements du bas du visage √† l'arr√™t 2",
                         Clignements2 = "Nombre de clignements des yeux √† l'arr√™t 2",
                         Yeux2 = "Nombre de mouvements des yeux √† l'arr√™t 2",
                         Tete2 = "Nombre de mouvements de la t√™te √† l'arr√™t 2",
                         Buste2 = "Nombre de mouvements du buste √† l'arr√™t 2",
                         Bras2 = "Nombre de mouvements des bras √† l'arr√™t 2",
                         Mains2 = "Nombre de mouvements des mains √† l'arr√™t 2",
                         Jambes2 = "Nombre de mouvements des jambes √† l'arr√™t 2",
                         Pieds2 = "Nombre de mouvements des pieds √† l'arr√™t 2",
                         Self_Adaptators2 = "Nombre de self-adaptators √† l'arr√™t 2",
                         Pas_P2_Cible = "Nombre de pas entre l'arr√™t 2 et la cible",
                         Temps_P2_Cible = "Temps entre l'arr√™t 2 et la cible (en secondes)",
                         Vitesse_P2_Cible = "Vitesse entre l'arr√™t 2 et la cible",
                         
                         EAFF_BES = "Score d'empathie affective (BES)",
                         Ecog_BES = "Score d'empathie cognitive (BES)",
                         CogSc_BES = "Score d'aspects cognitifs (BES)",
                         ContSc_BES = "Score de contagion √©motionnelle (BES)",
                         DecoSc_BES = "Score de d√©connexion √©motionnelle (BES)",
                         Total_BES = "Score total √† la BES (√âchelle d'Empathie Basique)",
                         
                         Machiavelisme_DDS = "Score de machiav√©lisme (DDS)",
                         Psychopathie_DDS = "Score de psychopathie (DDS)",
                         Narcissisme_DDS = "Score de narcissisme (DDS)",
                         Total_DDS = "Score total √† la DDS (Triade Sombre)",
                         
                         R_QI = "Score de r√©ponses √† la QPM38 (Matrices de Raven)",
                         QPM38_QI = "Score √† la QPM38 (Matrices de Raven)",
                         Centile_QI = "Centile √† la QPM38 (Matrices de Raven)",
                         
                         Activation_Generale_Trait_ADCL = "Score d'activation g√©n√©rale trait (ADCL)",
                         Serenite_Trait_ADCL = "Niveau de s√©r√©nit√© trait (ADCL)",
                         Anxiete_Trait_ADCL = "Niveau d'anxeit√© trait (ADCL)",
                         Autres_ADCL = "Autres niveaux (ADCL)",
                         Activation_Etat_ADCL = "Score d'activation g√©n√©rale √©tat (ADCL)",
                         Serenite_Etat_ADCL = "Niveau de s√©r√©nit√© √©tat (ADCL)",
                         Fatigue_Etat_ADCL = "Niveau de fatigue √©tat (ADCL)",
                         Excitation_ADCL = "Niveau d'arousal (ADCL)",
                         
                         Extraversion_BFI = "Score d'extraversion (BFI)",
                         Agreabilite_BFI = "Score d'agr√©abilit√© (BFI)",
                         Conscienseuxse_BFI = "Score de conscienciosit√© (BFI)",
                         Nevrotisme_BFI = "Score de n√©vrotisme (BFI)",
                         Ouverture_Esprit_BFI = "Score d'ouverture d'esprit (BFI)",
                         
                         Comedie_SM = "Score de com√©die (SM)",
                         Extraversion_SM = "Score d'extraversion (SM)",
                         PresDeSoi_SM = "Score de pr√©sentation de soi (SM)",
                         Total_SM = "Score total SM (Self-Monitoring)") # Nom des variables
```

## 5. Affichage des donn√©es

Affichage en un tableau

```{r print-data}
dt_Data <- data[1:35,1:62]
dt_Data %>%
  kbl(caption = "<b>Pr√©sentation du jeu de donn√©es.</b>") %>% # L√©gende
  kable_material(full_width = F) %>% # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%", height = "300px") # Barres de d√©filement
```

# II -- Statistiques descriptives

## 1. Globalit√©

R√©sum√© statistique des donn√©es

```{r print-summary-data}
summary(data[,! names(data) %in% c("Code")]) %>%
  kbl(caption = "<b>R√©sum√© statistique du jeu de donn√©es.</b>") %>%  # L√©gende
  kable_material(full_width = F) %>%  # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%") # Barre de d√©filement
```

¬†

R√©sum√© statistique des donn√©es selon le <i>Sexe</i>

```{r summary-data-sex}
#summary(data[,-1]) %>% split(.$Sexe) %>% map(summary)
#describeBy(data[,-1], data$Sexe)
dt_Sum_data_sex <- data[,] %>%
  group_by(Sexe) %>%
  skim() 

dt_Sum_data_sex <- dt_Sum_data_sex[-c(1,2),c(2:3,9:10,12:14,16)]
colnames(dt_Sum_data_sex) <- c("Variable", "Sexe", "Moyenne", "√âcart-Type", "Q1", "M√©diane", "Q3", "Histogramme")
dt_Sum_data_sex %>%
  kbl(caption = "<b>R√©sum√© statistique du jeu de donn√©es selon le <i>Sexe</i>.</b>") %>%  # L√©gende
  kable_material(full_width = F) %>%  # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%", height = "400px") # Barres de d√©filement
```

¬†

R√©sum√© statistique des donn√©es selon la <i>Condition</i>

```{r summary-data-cond}
dt_Sum_data_cond <- data[,-1] %>%
  group_by(Condition) %>%
  skim()

dt_Sum_data_cond <- dt_Sum_data_cond[-c(1,2),c(2:3,9:10,12:14,16)]
colnames(dt_Sum_data_cond) <- c("Variable", "Condition", "Moyenne", "√âcart-Type", "Q1", "M√©diane", "Q3", "Histogramme")
dt_Sum_data_sex%>%
  kbl(caption = "<b>R√©sum√© statistique du jeu de donn√©es selon la <i>Condition</i>.</b>") %>%  # L√©gende
  kable_material(full_width = F) %>%  # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%", height = "400px") # Barres de d√©filement
```

#### R√©sum√© statistique des donn√©es selon la <i>Condition</i> et par arr√™t

```{r mutate-arret}
dt_Info <- data[,2:4] # Infos
dt_Mouv_Arret1 <- data.frame(rowSums(data[,5:15])) # Mouvements arr√™t 1
colnames(dt_Mouv_Arret1) <- c("Nombre de mouvements √† l'arr√™t 1") # Nom ligne
dt_Pas1 <- data[,16:17] # Pas et vitesse 1
dt_Mouv_Arret2 <- data.frame(rowSums(data[,19:29])) # Mouvements arr√™t 2
colnames(dt_Mouv_Arret2) <- c("Nombre de mouvements √† l'arr√™t 2") # Nom ligne
dt_Mouv1 <- data[,5:15]
dt_Mouv2 <- data[,19:29]
dt_Pas2 <- data[,30:31] # Pas et vitesse 1
dt_BES <- data[,33:38] # BES
dt_DDS <- data[,c(39:42)] # DDS 
dt_Arousal <- data.frame(as.double(data[,53])) # Arousal
colnames(dt_Arousal) <- c("Niveau d'arousal")
dt_Sum_data <- do.call("cbind", list(dt_Info, dt_Mouv1, dt_Pas1, dt_Mouv2, dt_Pas2, dt_BES, dt_DDS, dt_Arousal))
dt_BES <- data[,c(33:34,36,38)] # BES
dt_Sum_data_mem <- do.call("cbind", list(dt_Info, dt_Mouv_Arret1, dt_Pas1, dt_Mouv_Arret2, dt_Pas2, dt_BES, dt_DDS, dt_Arousal))
rm(dt_Info, dt_Mouv_Arret1, dt_Pas1, dt_Mouv_Arret2, dt_Pas2, dt_BES, dt_DDS, dt_Arousal) 
```

```{r summary-data-cond-arret}
dt_Sum_data %>%
  tbl_summary(
    by = Condition,
    type = c(Haut_visage = "continuous", Bas_visage = "continuous", Bras = "continuous", Haut_visage2 = "continuous", Bras2 = "continuous", Pieds2 = "continuous", `Niveau d'arousal` = "continuous"),
    statistic = list(
      all_continuous() ~ "{mean} ({sd})",
      all_categorical() ~ "{n} / {N} ({p}%)"),
    missing = "no"
  ) %>%
  add_overall(col_label = "**Total**<br>N = {n}") %>% # Ajout et l√©gende du total
  modify_caption("<center><b>R√©sum√© statistique des donn√©es selon la <i>Condition</i> et par arr√™t.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**") %>% # Ent√™te
  modify_footnote(all_stat_cols() ~ "Moyenne (√âcart-Type)") # Abbr√©viations
```
R√©sum√© statistique concis

```{r summary-data-cond-arret-mem}
dt_Sum_data_mem %>%
  tbl_summary(
    by = Condition,
    type = c(`Niveau d'arousal` = "continuous"),
    statistic = list(
      all_continuous() ~ "{mean} ({sd})",
      all_categorical() ~ "{n} / {N} ({p}%)"),
    missing = "no"
  ) %>%
  add_overall(col_label = "**Total**<br>N = {n}") %>% # Ajout et l√©gende du total
  modify_caption("<center><b>R√©sum√© statistique des donn√©es selon la <i>Condition</i>.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**") %>% # Ent√™te
  modify_footnote(all_stat_cols() ~ "Moyenne (√âcart-Type)") # Abbr√©viations
```

¬†

üí° *R√©sume les statistiques de base de chaque variable :*

-   **Minimum** *: plus petite valeur observ√©e.*

-   **Q1** *(1er quantile) : au moins de 25% de l'√©chantillon sous cette valeur.*

-   **M√©diane** *(2√®me quantile) : au moins de 50% de l'√©chantillon sous cette valeur.*

-   **Moyenne**.

-   **Mode** *: valeur observ√©e avec le plus grand effectif (la plus r√©pandue).*

-   **Q3** *(3√®me quantile) : au moins de 75% de l'√©chantillon sous cette valeur.*

-   **Maximum** *: plus grande valeur observ√©e.*

-   **Valeurs manquantes** *: g√©n√©ralement "NA", mais remplac√© par des cases vierges ici.*

## 2. Par variable

### a) √Çge (sexe et condition)

Calcul de la variance totale

```{r var-tot}
var_age <- data.frame("Total", "", var(data$Age)) # Cr√©ation du tableau
colnames(var_age) <- c("Sexe", "Condition", "Variance") # Nom des colonnes
```

Calcul de la variance selon le sexe et la condition

```{r var-age}
Age_var <- aggregate (x = data$Age,
                      by = list(data$Sexe, data$Condition),
                      FUN = var
                      ) # Variance de l'√¢ge par sexe et condition
colnames(Age_var) <- c("Sexe", "Condition", "Variance") # Nom des colonnes
```

Tableau regroupant le tout

```{r tab-var}
Age_var <- rbind (Age_var, var_age) # Fusion des 2 tableaux
```

Affichage et mise en forme du tableau

```{r print-tab-var}
dt_Age_var <- Age_var[1:5,1:3] # S√©lection du tableau
dt_Age_var %>%
  kbl(caption = "<center><b>Variance de l'√¢ge selon le sexe et la condition.</b></center>") %>% # L√©gende
  kable_material(full_width = F) %>% # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) # Options de surlignage et rayures
```

### b) Indices comportementaux

Calcul de la variance et tableau

```{r var-ind}
Ind_var <- data.frame(data[,5:32] %>% summarise_if(is.numeric, var)) # Tableau r√©sum√© statistique
rownames(Ind_var) <- c("Variance") # Nom des lignes
```

Affichage et mise en forme du tableau

```{r print-var-ind}
dt_Ind_var <- Ind_var[1:28] # S√©lection du tableau
dt_Ind_var %>%
  kbl(caption = "<b>Variance des indices comportementaux.</b>") %>% # L√©gende
  kable_material(full_width = F) %>% # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%") # Barre de d√©filement
```

### c) Scores aux tests de personnalit√©

Calcul de la variance et tableau

```{r var-tests}
Tests_var <- data.frame(data[,33:62] %>% summarise_if(is.numeric, var)) # Tableau r√©sum√© statistique
rownames(Tests_var) <- c("Variance") # Nom des lignes
```

Affichage et mise en forme du tableau

```{r print-var-tests}
dt_Tests_var <- Tests_var[1:30] # S√©lection du tableau
dt_Tests_var %>%
  kbl(caption = "<b>Variance des scores aux tests de personnalit√©.</b>") %>% # L√©gende
  kable_material(full_width = F) %>% # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%") # Barre de d√©filement
```

Suppression des donn√©es aberrantes

```{r outliers}
datao <- data[,5:53] # Copie du dataframe
datao <- copy_labels(datao, data) # Copie des √©tiquettes

# Fonction de rep√©rage des valeurs aberrantes
find_outliers <- function(x) { 
  Q1 <- quantile(x, probs = .25) # Premier quantile (Q1)
  Q3 <- quantile(x, probs = .75) # Trois√®me quantile (Q3)
  IQR = Q3-Q1 # √âcart inter-quantile (Q3 - Q1)
  min = Q1 - (IQR * 1.5) # Borne inf√©rieure
  max = Q3 + (IQR*  1.5) # Borne sup√©rieure
  x > max | x < min # Si une valeur n'est pas dans l'intervalle, elle est un outlier / valeur aberrante
} 
 
# Fonction de suppression des valeurs aberrantes
remove_outliers <- function(df, cols = names(df)) { 
  for (col in cols) { 
    df <- df[!find_outliers(df[[col]]),] # Conserve les donn√©es pas aberrantes
  } 
}

# Appel de la fonction sur data et stockage dans un nouveau tableau
remove_outliers(datao, as.vector(names(datao))) 

```

# III -- Statistiques inf√©rentielles

## 1. Pr√©paration des donn√©es

Transformation des donn√©es dans les bons formats

```{r binarize}
datag <- data # Copie du jeu de donn√©es
datag <- copy_labels(data,datag) # Copie des √©tiquettes
datag$Condition <- ifelse(data$Condition == "Agression", 1, 0) # Remplacement des A par 1 et le reste (T) par 0
datag$Sexe <- ifelse(data$Sexe == "Masculin", 1, 0) # Remplacement des M par 1 et le reste (F) par 0
datag <- datag[,-c(1,43)] # Suppression du code sujet et du R de la QPM38 (qui sont li√©s lin√©airement)
```

## 2. Corr√©lations

### a) Pr√©cisions

#### Test

On utilise un **test de rang de Kendall** car il ne d√©pend pas de la distribution des donn√©es donc on n'a pas besoin de v√©rifier qu'elles soient Gaussiens (suivent une Loi Normale).

#### Utilisation

    cor.test(x, y, method="kendall") 

On peut stocker le r√©sultat dans une variable.

üí° *Mettre as.numeric(x) et pareil pour y vu que ce sont des variables √† facteurs / niveaux.*

    cor.V1.V2 <- cor.test(as.numeric(data$v1), as.numeric(data$V2), method="kendall")

#### Valeurs

-   **\\(z\\)** *= statistique de test*.
-   **\\(p-value\\)** *= p-valeur du test de corr√©lation (niveau d'erreur du test, plus elle est petite, mieux c'est "significatif" g√©n√©ralement quand elle est sous 0.05 ou 0.01).*
-   **\\(\\tau\\) (tau)** *= coefficient de corr√©lation.*

#### Interpr√©tation

-   Plus [tau]{.underline} est proche de **1** plus la relation **positive** est forte. Ils varient dans le [**m√™me** sens]{.underline}, si l'un augmente / diminue alors l'autre aussi.
-   Plus [tau]{.underline} est proche de **-1** plus la relation **n√©gative** est forte. Ils varient dans des [sens **oppos√©s**]{.underline}, quand l'un augmente / diminue, l'autre diminue / augmente.

### b) Matrices de corr√©lation

#### Sans les p-valeurs

```{r cor-matrix}
cor_matrix <- round(cor(datag, method = c("pearson", "kendall", "spearman")), 3) # Calcul des corr√©lations
dt_Cor_matrix <- data.frame(cor_matrix) # Transformation en tableau
```

Affichage et mise en forme du tableau

```{r print-cor-matrix}
dt_Cor_matrix %>%
  mutate_all(~ cell_spec(.x, color = case_when(.x == 1 ~ "white",
                                              .x <= -0.4 ~ "#A10A2E",
                                              .x <= -0.25 ~ "#EE80A7",
                                              .x >= 0.25 ~ "#043F6F",
                                              .x >= 0.4 ~ "#80CBEE",
                                              is.na(.x) ~ "white",
                                              TRUE ~ "lightgrey"))) %>% # Conditions de couleurs
  kable(escape = F, 
        caption = "<b>Corr√©lations entre toutes les variables.</b>") %>% # L√©gende
  column_spec(1, bold = T) %>% # Premi√®re colonne en gras
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%", height = "350px") # Barres de d√©filement
```

¬†

#### Avec les p-valeurs

```{r cor-matrix-p}
cor_matrix_p <- rcorr(as.matrix(datag)) # Matrice de corr√©lation avec les p-valeurs
```

Transformer en tableau

```{r dt-cor-matrix-p}
CorMatrix <- function(cormat, pmat) { # Fonction de transformation de la matrice en tableau
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut], # cormat : matrice des coefficients de corr√©lation
    p = pmat[ut] # pmat : matrice des p-valeurs
    )
  }
```

Ordonner et arrondir les donn√©es

```{r proc-cor-matrix-p}
dt_Cor_matrix_p <- CorMatrix(cor_matrix_p$r, cor_matrix_p$P) # Application de la fonction de trnasformation en tableau
dt_Cor_matrix_p[is.na(dt_Cor_matrix_p)] <- 0 # Remplacement des cases vides par des 0 
dt_Cor_matrix_p$cor <- round(dt_Cor_matrix_p$cor,3) # Arrondi des coefficients de corr√©lations √† 3 d√©cimales
dt_Cor_matrix_p$p <- round(dt_Cor_matrix_p$p,4) # Arrondi des p-valeurs √† 4 d√©cimales
dt_Cor_matrix_p <- dt_Cor_matrix_p[order(dt_Cor_matrix_p$p),] # Rangement croissant des valeurs selon les p-valeurs
```

Affichage et mise en forme du tableau ¬†\
<i>Les corr√©lations √©lev√©es entre les scores des √©chelles et leurs totaux sont normales et permettent de v√©rifier la coh√©rence des donn√©es. De m√™me pour certaines valeurs au sein de la BES.</i>

```{r print-cor-matrix-p}
dt_Cor_matrix_p %>%
  mutate(
    cor = cell_spec(cor, color = case_when(cor == 1 ~ "white",
                                           cor <= -0.4 ~ "#A10A2E",
                                           cor <= -0.25 ~ "#EE80A7",
                                           cor >= 0.25 ~ "#043F6F",
                                           cor >= 0.4 ~ "#80CBEE",
                                           is.na(cor) ~ "white",
                                           TRUE ~ "lightgrey")),
    p = cell_spec(p, color = case_when(p > 0.1 ~ "lightgrey",
                                       p <= 0.01 ~ "#266617",
                                       p <= 0.05 ~ "#3FA329",
                                       p <= 0.1 ~ "#D5F0C9",
                                       is.na(p) ~ "white",
                                       TRUE ~ "lightgrey"))) %>% # Conditions de couleurs
  kable(escape = F, 
        caption = "<b><center>Corr√©lations entre toutes les variables et p-valeurs.</b></center>", 
        col.names = c("Variable 1", "Variable 2", "Coefficient de corr√©lation", "p-valeur")) %>% # L√©gende et noms des colonnes 
  column_spec(1, color = "white") %>% # Couleur de la premi√®re colonne (ordre des valeurs)
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%  # Options de surlignage et rayures
  scroll_box(width = "100%", height = "350px") # Barres de d√©filement
```

```{r plot-cor-matrix, echo = FALSE}
#Repr√©senter visuellement sans les p-valeurs
#corrplot(cor_matrix, type = "upper", order = "hclust", 
         #tl.col = "black", tl.srt = 90)
```

```{r plot-cor-matrix-p, echo = FALSE}
#Repr√©senter visuellement avec les p-valeurs
#corrplot(cor_matrix_p$r, type="upper", order="hclust", 
         #p.mat = cor_matrix_p$P, sig.level = 0.01, insig = "blank")
```

### c) Corr√©lation entre <i>Condition</i> et les autres variables

#### Sans les p-valeurs

```{r cor-cond}
cor_cond <- data.frame(cor(datag[ , colnames(datag) != "Condition"], datag$Condition)) # Tableau de corr√©lation entre la condition et les autres variables
colnames(cor_cond) <- "Condition" # Noms des colonnes
```

¬†

#### Filtrage des corr√©lations (\< -0.25 ou \> 0.25)

```{r filter-cor-cond}
dt_Cor_cond_filter <- cor_cond %>% # Nouveau tableau
  filter(Condition < -0.25  | Condition > 0.25 ) # Condition (plus de 25% ou moins de -25% pour les corr√©lations n√©gatives)
dt_Cor_cond_filter$Condition <- round(dt_Cor_cond_filter$Condition,3) # Arrondi des coefficients de corr√©lations √† 3 d√©cimales
```

Affichage et mise en forme du tableau

```{r dt-filter-cor-cond}
row.names(dt_Cor_cond_filter) <- c("Mouvements du haut de visage √† l'arr√™t 1", "Mouvement de jambes √† l'arr√™t 1", "Mouvements de pieds √† l'arr√™t 1", "Mouvement de jambes √† l'arr√™t 2", "Nombre de pas entre l'arr√™t 2 et la cible", "Vitesse entre l'arr√™t 2 et la cible", "Score total √† la BES (√âchelle d'Empathie)", "Score d'empathie affective (BES)", "Score de contagion √©motionnelle (BES)") # Noms des lignes 
dt_Cor_cond_filter %>% 
  mutate(
    Condition = cell_spec(Condition, color = case_when(
                                                       Condition <= -0.4 ~ "#A10A2E",
                                                       Condition <= -0.25 ~ "#EE80A7",
                                                       Condition >= 0.4 ~ "#043F6F",
                                                       Condition >= 0.25 ~ "#80CBEE",
                                                       is.na(Condition) ~ "white",
                                                       TRUE ~ "lightgrey")))  %>% # Conditions couleurs
  kable(escape = F, 
        caption = "<center><b>Corr√©lations sup√©rieures √† 25% entre la <i>Condition</i> et les autres variables.</b></center>") %>% # L√©gende
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) # Options de surlignage et rayures
```

Repr√©senter visuellement

```{r plot-filter-cor-cond}
dt_Cor_cond_filter$Variable <- rownames(dt_Cor_cond_filter) # Ajout des noms de lignes
dt_Cor_cond_filter %>% 
  mutate(Variable = factor(Variable, levels = Variable[order(Condition)])) %>% # Rangement croissant 
  ggplot(aes(x = Variable, y = Condition)) + # Cr√©ation d'un graphique
    geom_bar(stat = "identity", 
             fill = "lightskyblue1", 
             alpha = 0.8, 
             width = 0.5) + # Options visuelles
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + # L√©gendes des abscisses √† la verticale
    ylab("Corr√©lation avec la Condition") + # Titre des ordonn√©es
    xlab("Variable") + # Titre des abscisses
    ggtitle("Corr√©lations sup√©rieures √† 25% entre la Condition et les autres variables.") # Titre
```

¬†

#### Avec les p-valeurs

```{r cor-matrix-cond-p}
pvals <- sapply(datag[-1], function(x) corr.test(x, datag$Condition)$p) # Calcul des p-valeurs
pvals <- round(pvals,4) # Arrondi des p-valeurs √† 4
rvals <- sapply(datag[-1], function(x) corr.test(x, datag$Condition)$r) # Calcul des coefficients de corr√©lation
rvals <- round(rvals,3) # Arrondi des coefficients de corr√©lation √† 3
```

Ordonner et arrondir les donn√©es

```{r proc-cor-matrix}
dt_Cor_matrix_cond_p <- data.frame(rbind(rvals, pvals)) # Cr√©ation d'un tableau avec les coefficients de corr√©lation et p-valeurs
dt_Cor_matrix_cond_p <- t(dt_Cor_matrix_cond_p) # Inversion des lignes et colonnes
dt_Cor_matrix_cond_p <- data.frame(dt_Cor_matrix_cond_p) # Tableau avec l'inversion
dt_Cor_matrix_cond_p <- dt_Cor_matrix_cond_p[order(dt_Cor_matrix_cond_p$pvals),] # Rangement croissant des valeurs selon les p-valeurs
```

Affichage et mise en forme du tableau

```{r print-cor-matrix-cond-p}
dt_Cor_matrix_cond_p %>%
  mutate(
    rvals = cell_spec(rvals, color = case_when(rvals == 1 ~ "grey",
                                               rvals <= -0.4 ~ "#A10A2E",
                                               rvals <= -0.25 ~ "#EE80A7",
                                               rvals >= 0.4 ~ "#043F6F",
                                               rvals >= 0.25 ~ "#80CBEE",
                                               is.na(rvals) ~ "white",
                                               TRUE ~ "lightgrey")),
    pvals = cell_spec(pvals, color = case_when(pvals > 0.1 ~ "grey",
                                               pvals <= 0.01 ~ "#266617",
                                               pvals <= 0.05 ~ "#3FA329",
                                               pvals <= 0.1 ~ "#D5F0C9",
                                               is.na(pvals) ~ "white",
                                               TRUE ~ "lightgrey"))) %>% # Conditions des couleurs
  kable(escape = F, 
        caption = "<b>Corr√©lations entre <i>Condition</i> et les autres variables et p-valeurs.</b>", 
        col.names = c("Coefficient de corr√©lation", "p-valeur")) %>% # L√©gende et noms des colonnes
  column_spec(1,  bold = T) %>% # Premi√®re colonne en gras
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%", height = "350px") # Barres de d√©filement
```

## 3. ANOVA

### a) Test de normalit√© (Shapiro-Wilk)

On commence par tester la normalit√© (r√©partition selon une loi gaussienne) des donn√©es.
H0 : l'√©chantillon suit une loi normale. Donc si le test renvoie une p-value non significative, l'√©chantillon suit une loi normale.
Dans tous les cas, d'apr√®s le th√©or√®me central limite, l'√©chantillon est assez grand pour √™tre consid√©r√© comme tel. On peut donc lui appliquer les tests que l'on applique aux √©chantillons gaussiens.

```{r aov-shapiro, results = 'hide'}
set.seed(321) # pour que le code soit reproductible avec les m√™mes valeurs
apply(datag, 2, shapiro.test) # 2 pour pr√©ciser qu'on applique aux colonnes
```

### b) Test d'homosc√©dasticit√© (Levene)

On v√©rifie ensuite l'homosc√©dasticit√© (ou homog√©n√©it√© des variances) des diff√©rents groupes.
H0 : les variances sont homog√®nes (√©gales) dans tous les groupes. Donc si le test renvoie une p-value non significative, les variances sont homog√®nes.

```{r aov-levene}
leveneTest(Jambes2 ~ Condition, data = data)
leveneTest(EAFF_BES ~ Condition, data = data)
leveneTest(ContSc_BES ~ Condition, data = data)
```

### c) Analyse de la Variance

L'ANOVA nous permet de comparer les moyennes de plusieurs groupes. Elle s'effectue sur des √©chantillons gaussiens ou consid√©r√©s comme gaussiens (ou normalis√©s).

#### Afficher les p-valeurs des ANOVA possibles

```{r all-aov-pval, results = 'hide'}
formulaov <- lapply(colnames(datag)[2:ncol(datag)], function(x) as.formula(paste0(x, " ~ Condition"))) # Cr√©ation de la formule pour l'ANOVA
resaov <- lapply(formulaov, function(x) summary(aov(x, data = datag))) # Application au jeu de donn√©es
names(resaov) <- format(formulaov) # Nom des r√©sultats
pvalaov <- unlist(lapply(resaov, function(x) x[[1]]$"Pr(>F)"[1])) # p-valeurs
dt_aov = data.frame(
  Variable = sub(' ~ Condition', '', names(pvalaov)),
  pvalue = pvalaov) # Tableau des p-valeurs
```

#### Afficher toutes les ANOVA possibles

```{r all-aov-summ, results = 'hide'}
for (i in 2:ncol(datag)) {
   formula <- as.formula(paste(colnames(datag)[i], " ~ Condition", sep=""))
   model <- aov(formula, data = datag)

   cat("\n-----\n\n")
   cat(colnames(datag)[i])
   cat("\n")
   print(summary(model))
}
```

### d) Test de diff√©rence de moyennes (Newman-Keuls)

Ce test permet d'identifier les moyennes intergroupes significatives. On l'utilise g√©n√©ralement comme test post-hoc sur les ANOVA significatives.

### e) Test de Welch (t-test)

Pour les ANOVA significatives, on effectue un t-test post-hoc afin de comparer les moyennes sans hypoth√®se (d'√©galit√©) pr√©alable. Dans le cas de deux groupes √† variances in√©gales, on utilise Welch et non Student.

### f) Ajustement de Bonferroni 

Cette m√©thode est aussi un test dit post-hoc, permet d'ajuster les seuils de significativit√© des ANOVA significatives.

#### Afficher les ANOVA significatives

```{r best-aov}
summary(aov(Jambes2 ~ Condition, data = datag))
```

```{r best-aov2}
summary(aov(EAFF_BES ~ Condition, data = datag))
```

```{r best-aov3}
summary(aov(ContSc_BES ~ Condition, data = datag))
```

Mouvements des jambes √† l'arr√™t 2

```{r aov-jambes2}
data %>%
  select(Condition, Jambes2) %>%
  tbl_summary(
    by = Condition, 
    missing = "no"
  ) %>%
  add_p(all_continuous() ~ "aov") %>% # p-valeurs ANOVA
  bold_p() %>% # p-valeurs significatives en gras    
  add_overall(col_label = "**Total**<br>N = {n}") %>% # Ajout et l√©gende du total
  modify_caption("<center><b>ANOVA √† un facteur entre la <i>Condition</i> et les mouvements des jambes √† l'arr√™t 2.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**", statistic = "**Statistique de Test**") %>% # Ent√™te
  modify_footnote(all_stat_cols() ~ "M√©diane (√âcart Inter-Quartile)", p.value ~ "ANOVA √† un facteur") %>% # Abbr√©viations
  modify_fmt_fun(statistic ~ style_sigfig) %>% # Format des chiffres
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") # Niveau de significativit√©

print(SNK.test(aov(Jambes2 ~ Condition, data = datag),"Condition", group = TRUE)) # Test de Newman-Keuls
print(t.test(Jambes2 ~ Condition, data = data, alternative = "two.sided")) # Test de Welch
print(pairwise.t.test(data$Jambes2, data$Condition, p.adjust.method = "bonferroni")) # Ajustement de Bonferroni
```

Taille d'effet
```{r aov-jambes2-eta}
etaSquared(aov(Jambes2 ~ Condition, data = data))
```

Score d'empathie affective (BES)

```{r aov-eaff}
data %>%
  select(Condition, EAFF_BES) %>%
  tbl_summary(
    by = Condition, 
    missing = "no"
  ) %>%
  add_p(all_continuous() ~ "aov") %>% # p-valeurs ANOVA
  bold_p() %>% # p-valeurs significatives en gras    
  add_overall(col_label = "**Total**<br>N = {n}") %>% # Ajout et l√©gende du total
  modify_caption("<center><b>ANOVA √† un facteur entre la <i>Condition</i> et le 
score d'empathie affective (BES).</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**", statistic = "**Statistique de Test**") %>% # Ent√™te
  modify_footnote(all_stat_cols() ~ "M√©diane (√âcart Inter-Quartile)", p.value ~ "ANOVA √† un facteur") %>% # Abbr√©viations
  modify_fmt_fun(statistic ~ style_sigfig) %>% # Format des chiffres
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") # Niveau de significativit√©

print(SNK.test(aov(EAFF_BES ~ Condition, data = data),"Condition", group = TRUE)) # Test de Newman-Keuls
print(t.test(EAFF_BES ~ Condition, data = data, alternative = "two.sided")) # Test de Welch
print(pairwise.t.test(data$EAFF_BES, data$Condition, p.adjust.method = "bonferroni")) # Ajustement de Bonferroni
```

Taille d'effet
```{r aov-eaff-eta}
etaSquared(aov(EAFF_BES ~ Condition, data = data))
```

Score de contagion √©motionnelle (BES)

```{r aov-contsc}
data %>%
  select(Condition, ContSc_BES) %>%
  tbl_summary(
    by = Condition, 
    missing = "no"
  ) %>%
  add_p(all_continuous() ~ "aov") %>% # p-valeurs ANOVA
  bold_p() %>% # p-valeurs significatives en gras    
  add_overall(col_label = "**Total**<br>N = {n}") %>% # Ajout et l√©gende du total
  modify_caption("<center><b>ANOVA √† un facteur entre la <i>Condition</i> et le score de contagion √©motionnelle (BES).</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**", statistic = "**Statistique de Test**") %>% # Ent√™te
  modify_footnote(all_stat_cols() ~ "M√©diane (√âcart Inter-Quartile)", p.value ~ "ANOVA √† un facteur") %>% # Abbr√©viations
  modify_fmt_fun(statistic ~ style_sigfig) %>% # Format des chiffres
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") # Niveau de significativit√©

print(SNK.test(aov(ContSc_BES ~ Condition, data = data),"Condition", group = TRUE)) # Test de Newman-Keuls
print(t.test(ContSc_BES ~ Condition, data = data, alternative = "two.sided")) # Test de Welch
print(pairwise.t.test(data$ContSc_BES, data$Condition, p.adjust.method = "bonferroni")) # Ajustement de Bonferroni
```

Taille d'effet
```{r aov-cont-eta}
etaSquared(aov(ContSc_BES ~ Condition, data = data))
```

## 4. Test de Wilcoxon

Ce test permet de comparer des moyennes sans v√©rifier la normalit√© ou l'homosc√©dasticit√©. On l'utilise pour comparer les moyennes entre les 2 conditions qui semblent diff√©rentes.

```{r wilcox-haut-vis}
wilcox.test(data$Haut_visage[data$Condition == "Agression"], data$Haut_visage[data$Condition == "T√©l√©phone"])
```

```{r wilcox-pas1}
wilcox.test(data$Pas_P1_P2[data$Condition == "Agression"], data$Pas_P1_P2[data$Condition == "T√©l√©phone"])
```
```{r wilcox-jambes2}
wilcox.test(data$Jambes2[data$Condition == "Agression"], data$Jambes2[data$Condition == "T√©l√©phone"])
```

```{r wilcox-pas2}
wilcox.test(data$Pas_P2_Cible[data$Condition == "Agression"], data$Pas_P2_Cible[data$Condition == "T√©l√©phone"])
```

```{r wilcox-eaff-bes}
wilcox.test(data$EAFF_BES[data$Condition == "Agression"], data$EAFF_BES[data$Condition == "T√©l√©phone"])
```

```{r wilcox-tot-bes}
wilcox.test(data$Total_BES[data$Condition == "Agression"], data$Total_BES[data$Condition == "T√©l√©phone"])
```

## 4. Alpha de Cronbach

### a) Pr√©cisions

L'$\alpha$ (alpha) de Cronbach v√©rifie la coh√©rence (ou l'homog√©n√©it√©) d'une √©chelle psychom√©trique. Autrement dit, √† quel point tous les √©l√©ments convergent vers la m√™me intensit√© de r√©ponse. L'alpha de Cronbach se situe entre 0 et 1. Plus il tend vers 1, plus le questionnaire est homog√®ne.

### b) Donn√©es

```{r data-cron}
cron = read.csv(file = 'https://raw.githubusercontent.com/astridgcn/R-Behavioral-Analysis/main/Cronbach.csv', sep = ";", check.names = F, header = TRUE) 
```

### c) Calculs

#### √âchelle d'Empathie Basique (BES)

```{r cron-bes}
print("Alpha de Cronbach pour l'empathie affective (BES)")
cronbach(cron[c("B01R", "B02", "B04R", "B05", "B07", "B08", "B11", "B13R", "B15", "B17", "B18R")])
print("Alpha de Cronbach pour l'empathie cognitive (BES)")
cronbach(cron[c("B03", "B06R", "B09", "B10", "B12", "B14", "B16", "B19R", "B20R")])
print("Alpha de Cronbach pour la contagion √©motionnelle (BES)")
cronbach(cron[c("B02", "B04", "B05", "B11", "B15", "B17")])
```

#### Triade Sombre (DDS)

```{r cron-dds}
print("Alpha de Cronbach pour le machiav√©lisme (DDS)")
cronbach(cron[c("D01", "D02", "D03", "D04")])
print("Alpha de Cronbach pour le narcissisme (DDS)")
cronbach(cron[c("D05", "D06", "D07", "D08")])
print("Alpha de Cronbach pour la psychopathie (DDS)")
cronbach(cron[c("D09", "D10", "D11", "D12")])
```

#### Check List d'Activation / D√©sactivation (ADCL)

```{r cron-arous}
print("Alpha de Cronbach pour l'arousal (AD ACL)")
cronbach(cron[c("E09", "E17", "E26")])
```

#### Inventaire des Cinq grands Facteurs de Personnalit√© (BFI)

```{r cron-bfi}
cronbach(data[,54:58])
```

#### √âchelle de Self-Monitoring (BFI)

```{r cron-sm}
cronbach(data[,59:62])
```

# IV -- R√©gressions

## 1. Pr√©cisions

#### M√©thodes

üí° Il existe plusieurs m√©thodes, notamment :

-   Tester les mod√®les possibles un par un (mais on poss√®de 60 variables explicatives possibles).

-   M√©thode **ascendante** : partir du mod√®le le plus petit mod√®le et ajouter des variables explicatives.

-   M√©thode **descendante** : partir du mod√®le avec toutes les variables explicatives possibles et r√©duire petit √† petit.

Cr√©ation des mod√®les de r√©gression :

-   **Min** : la variable *Condition* (par exemple) s'explique par elle-m√™me.

-   **Max** : la variable *Condition* (par exemple) s'explique gr√¢ce √† toutes les autres variables.

#### Crit√®res pertinents

On utilise ensuite un crit√®re de vraisemblance pour estimer l'utilit√© du mod√®le :

-   **AIC** : Akaike Information Criterion. $$
    \begin{align}
      \tag{1}
        -2\ \ln(\widehat{L}) + 2k
    \end{align}
    $$
-   **BIC** : Bayesian Information Criterion. $$
    \begin{align}
      \tag{2}
        -2\ \ln(\widehat{L}) + k \ \ln(n)
    \end{align}
    $$

Ceux-ci doivent √™tre minimis√©s pour obtenir le meilleur mod√®le.

Autres crit√®res pertinents √† l'√©tude des mod√®les :

-   $R^2_{ajust√©}$ : coefficient mesurant l'ajustement du mod√®le aux donn√©es (et permet de comparer des mod√®les avec un nombre de variables diff√©rent car s'ajuste selon les donn√©es).

-   $D(y, \widehat\mu)$ : d√©viance (√† quel point on s'√©loigne du mod√®le parfait).

-   $\sigma$ : √©cart-type (racine de la variance) des r√©sidus (√©cart entre les donn√©es r√©elles et pr√©dires) du mod√®le.

-   **\\(p-value\\)** : p-valeur du test de corr√©lation (niveau d'erreur du test, plus elle est petite, mieux c'est "significatif" g√©n√©ralement quand elle est sous 0.05 ou 0.01).

üí° *Ces crit√®res l√† s'√©tudient lorsqu'on a obtenu / s√©lectionn√© le meilleur mod√®le possible.*

## 2. Tous les mod√®les possibles pour toutes les variables

```{r all-mod, results = 'hide'}
 # Cr√©ation de la liste de mod√®les avec +20% de R2 ajust√©
best_models = list()

# Incr√©mentation
i = 1

# Recherche des meilleurs mod√®les pour chaque variable
while (i <= length(datag)) {
#for (i in range(rangeA)) {
  print(variable.names(datag[i]))
  modele_min = lm(datag[,i] ~ 1, data = datag) # Cr√©ation du mod√®le de r√©gression minimal
  modele_max = lm(datag[,i] ~ ., data = datag) # Cr√©ation du mod√®le de r√©gression maximal
  modele_best = step(modele_min, scope = list(lower = modele_min, upper = modele_max), data = datag, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
  print(summary(modele_best)) # R√©sum√© du meilleur mod√®le
  name_mod = paste("modele_best", variable.names(datag[i]), sep = "_") # Cr√©ation du nom du mod√®le
  assign(name_mod, modele_best) # Stockage du mod√®le avec le bon nom
  adj.r = summary(modele_best)$adj.r.squared
  if (is.na(adj.r)){ # Si le R 2ajust√© est vide
    
  }
  else {
    if (adj.r >= 0.2) { # Si le R 2ajust√© sup√©rieur √† 0.2
      best_models = c(best_models, name_mod)
    }
  }
  rm(modele_min, modele_max, modele_best, name_mode) # Suppression des variables pour √©viter les erreurs
  i = i + 1 # Incr√©mentation
}
```

## 3. <i>Agression</i> et toutes les variables

Pr√©parer les donn√©es

```{r reg-prep}
datag <- datag[,! names(datag) %in% c("Code", "Total_BES", "Total_DDS", "Total_SM", "Vitesse_P1_P2", "Vitesse_P2_Cible")] # Retirer le code sujet et les totaux des tests
```

### a) R√©gression logistique multiple

#### Mod√®le minimal

Cr√©ation

```{r log-min, results = 'hide'}
modele_log_min = glm(datag$Condition ~ 1, data = datag, family = binomial) # Cr√©ation du mod√®le de r√©gression logistique multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r log-min-summary}
summary(modele_log_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

Cr√©ation

```{r log-max, results = 'hide'}
modele_log_max = glm(datag$Condition ~ ., data = datag, family = binomial) # Cr√©ation du mod√®le de r√©gression logistique multiple maximal (toutes les variables explicatives)
alias(modele_log_max) # R√©sum√© du mod√®le
summary(modele_log_max) # Autre r√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode descendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r log-best, results = 'hide'}
modele_log_best <- step(modele_log_max, data = datag, direction = "backward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le maximal (en √¥tant des variables)
```

Meilleur mod√®le (AIC = 22)

```{r log-best-summary}
summary(modele_log_best)
tbl_regression(modele_log_best, 
               #label = term_labels(modele_log_best), # Nom des lignes
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression logistique multiple le plus performant (AIC = 22) pour pr√©dire la <i>Condition</i>.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(estimate = "OR = Rapports des Chances", std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations  
  bold_p() %>% # p-valeurs significatives en gras   
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(include = c(AIC)) # Statistiques du mod√®le
```

### b) R√©gression lin√©aire multiple

#### Mod√®le minimal

Cr√©ation

```{r min, results = 'hide'}
modele_min = lm(datag$Condition ~ 1, data = datag) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal  (aucune variable explicative)
```

R√©sum√©

```{r min-summary}
summary(modele_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{r max, results = 'hide'}
modele_max = lm(Condition ~ ., data = datag) # # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_max) # R√©sum√© du mod√®le
summary(modele_max) # Autre r√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r best, results = 'hide'}
modele_best <- step(modele_min, scope = list(lower = modele_min, upper = modele_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = -596.59)

```{r best-summary}
tbl_regression(modele_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs) 
  bold_p() %>% # p-valeurs significatives en gras   
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = -596.59) pour pr√©dire la <i>Condition</i>.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") # Niveau de significativit√©
```

## 4. <i>Condition</i> et variables avec une corr√©lation sup√©rieure √† 25%

### a) R√©gression logistique multiple

#### Mod√®le minimal

Cr√©ation

```{r log-sel-min, results = 'hide'}
modele_log_sel_min = glm(datag$Condition ~ 1, data = datag, family = binomial) # Cr√©ation du mod√®le de r√©gression logistique multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r log-sel-min-summary}
summary(modele_log_sel_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

Cr√©ation

```{r log-sel-max, results = 'hide'}
modele_log_sel_max = glm(datag$Condition ~ Haut_visage + Jambes + Pieds + Jambes2 + Pas_P2_Cible + EAFF_BES + ContSc_BES , data = datag, family = binomial) # Cr√©ation du mod√®le de r√©gression logistique multiple maximal (toutes les variables explicatives)
alias(modele_log_sel_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r log-sel-max-summary}
summary(modele_log_sel_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode descendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r log-sel-best, results = 'hide'}
modele_log_sel_best <- step(modele_log_sel_max, data = datag, direction = "backward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le maximal (en √¥tant des variables)
```

Meilleur mod√®le (AIC = 26.25)

```{r log-sel-best-summary}
summary(modele_log_sel_best)
tbl_regression(modele_log_sel_best, 
               exponentiate = T,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression logistique multiple le plus performant (AIC = 26.25) pour pr√©dire la <i>Condition</i> avec les variables fortement corr√©l√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(estimate = "OR = Rapports des Chances", std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(include = c(AIC)) # Statistiques du mod√®le
```

### b) R√©gression lin√©aire multiple

#### Mod√®le minimal

Cr√©ation

```{r sel-min, results = 'hide'}
modele_sel_min = lm(datag$Condition ~ 1, data = datag) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r sel-min-summary}
summary(modele_sel_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{r sel-max, results = 'hide'}
modele_sel_max = lm(datag$Condition ~ Haut_visage + Jambes + Pieds + Jambes2 + Pas_P2_Cible + EAFF_BES + ContSc_BES, data = datag) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_sel_max) # R√©sum√© du mod√®le
summary(modele_sel_max) # Autre r√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r sel-best, results = 'hide'}
modele_sel_best <- step(modele_sel_min, scope = list(lower = modele_sel_min, upper = modele_sel_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 41.16)

```{r sel-best-summary}
summary(modele_sel_best)
tbl_regression(modele_sel_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 41.16) pour pr√©dire la <i>Condition</i> avec les variables fortement corr√©l√©es et expliquant 38.89% de la variance des donn√©es.</b></center>") %>%# L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-sel-best}
summary.aov(modele_sel_best) # R√©sum√©
```

## 5. <i>Condition</i> et les 6 scores cibl√©s (BES, DDS, arousal)

### a) R√©gression logistique multiple

#### Mod√®le minimal

Cr√©ation

```{r log-tests-min, results = 'hide'}
modele_log_tests_min = glm(datag$Condition ~ 1, data = datag, family = binomial) # Cr√©ation du mod√®le de r√©gression logistique multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r log-tests-min-summary}
summary(modele_log_tests_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

Cr√©ation

```{r log-tests-max, results = 'hide'}
modele_log_tests_max = glm(datag$Condition ~ EAFF_BES + Ecog_BES + ContSc_BES + Machiavelisme_DDS + Narcissisme_DDS + Psychopathie_DDS + Excitation_ADCL, data = datag, family = binomial) # Cr√©ation du mod√®le de r√©gression logistique multiple maximal (toutes les variables explicatives)
alias(modele_log_tests_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r log-tests-max-summary}
summary(modele_log_tests_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode descendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r log-tests-best, results = 'hide'}
modele_log_tests_best <- step(modele_log_tests_max, data = datag, direction = "backward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le maximal (en √¥tant des variables)
```

Meilleur mod√®le (AIC = 41.73)

```{r log-tests-best-summary}
summary(modele_log_tests_best)
tbl_regression(modele_log_tests_best, 
               exponentiate = T, # Nom des lignes
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression logistique multiple le plus performant (AIC = 41.73) pour pr√©dire la <i>Condition</i> avec les 6 scores cibl√©s.</b></center>")%>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(estimate = "OR = Rapports des Chances", std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(include = c(AIC)) # Statistiques du mod√®le
```

### b) R√©gression lin√©aire multiple

#### Mod√®le minimal

Cr√©ation

```{r tests-min, results = 'hide'}
modele_tests_min = lm(datag$Condition ~ 1, data = datag) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r tests-min-summary}
summary(modele_tests_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{r tests-max, results = 'hide'}
modele_tests_max = lm(datag$Condition ~ EAFF_BES + Ecog_BES + Machiavelisme_DDS + + Narcissisme_DDS + Psychopathie_DDS + Excitation_ADCL, data = datag) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_tests_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r tests-max-summary}
summary(modele_tests_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r tests-best, results = 'hide'}
modele_tests_best <- step(modele_tests_min, scope = list(lower = modele_tests_min, upper = modele_tests_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 46.81)

```{r tests-best-summary}
summary(modele_tests_best)
tbl_regression(modele_tests_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 46.81) pour pr√©dire la <i>Condition</i> avec les 6 scores cibl√©s et expliquant 24.52% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-tests-best}
summary.aov(modele_tests_best) # R√©sum√©
```

## 6. Scores cibl√©s (BES, DDS, arousal) et indices non-verbaux

Ces scores √©tant des variables qualitatives discr√®tes, on effectue des r√©gressions lin√©aires multiples.

### a) Pr√©paration des donn√©es

```{r data-scores}
datas <- datag[,2:29]
datas <- copy_labels(datas, datag) # Copie des √©tiquettes
```

### b) Score d'empathie affective (BES)

#### Mod√®le minimal

Cr√©ation

```{r eaff-min, results = 'hide'}
modele_eaff_min = lm(datag$EAFF_BES ~ 1, data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r eaff-min-summary}
summary(modele_eaff_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{r eaff-max, results = 'hide'}
modele_eaff_max = lm(datag$EAFF_BES ~ ., data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_eaff_max)  # R√©sum√© du mod√®le
```

R√©sum√©

```{r eaff-max-summary}
summary(modele_eaff_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r eaff-best, results = 'hide'}
modele_eaff_best <- step(modele_eaff_min, scope = list(lower = modele_eaff_min, upper = modele_eaff_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 176.29)

```{r eaff-best-summary}
summary(modele_eaff_best)
tbl_regression(modele_eaff_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 176.29) pour pr√©dire le <i>score d'empathie affective (BES)</i> et expliquant 46.2% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-mod-eaff}
summary.aov(modele_eaff_best) # R√©sum√©
```

### c) Score d'empathie cognitive (BES)

#### Mod√®le minimal

Cr√©ation

```{r ecog-min, results = 'hide'}
modele_ecog_min = lm(datag$Ecog_BES ~ 1, data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r ecog-min-summary}
summary(modele_ecog_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{r ecog-max, results = 'hide'}
modele_ecog_max = lm(datag$Ecog_BES ~ ., data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_ecog_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r ecog-max-summary}
summary(modele_ecog_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r ecog-best, results = 'hide'}
modele_ecog_best <- step(modele_ecog_min, scope = list(lower = modele_ecog_min, upper = modele_ecog_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 185.54)

```{r ecog-best-summary}
summary(modele_ecog_best)
tbl_regression(modele_ecog_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 185.54) pour pr√©dire le <i>score d'empathie cognitive (BES)</i> et expliquant 58.12% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-mod-ecog}
summary.aov(modele_ecog_best) # R√©sum√©
```

### d) Score de contagion √©motionnelle (BES)

#### Mod√®le minimal

Cr√©ation

```{r contsc-min, results = 'hide'}
modele_contsc_min = lm(datag$ContSc_BES ~ 1, data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r contsc-min-summary}
summary(modele_contsc_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{r contsc-max, results = 'hide'}
modele_contsc_max = lm(datag$ContSc_BES ~ ., data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_contsc_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r contsc-max-summary}
summary(modele_contsc_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r contsc-best, results = 'hide'}
modele_contsc_best <- step(modele_contsc_min, scope = list(lower = modele_contsc_min, upper = modele_contsc_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 199)

```{r contsc-best-summary}
summary(modele_contsc_best)
tbl_regression(modele_contsc_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 199) pour pr√©dire le <i>score de contagion √©motionnelle (BES)</i> et expliquant 35.8% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-mod-contsc}
summary.aov(modele_contsc_best) # R√©sum√©
```

### e) Score de machiav√©lisme (DDS)

#### Mod√®le minimal

Cr√©ation

```{r machia-min, results = 'hide'}
modele_machia_min = lm(datag$Machiavelisme_DDS ~ 1, data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r machia-min-summary}
summary(modele_machia_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{r machia-max, results = 'hide'}
modele_machia_max = lm(datag$Machiavelisme_DDS ~ ., data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_machia_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r machia-max-summary}
summary(modele_machia_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r machia-best, results = 'hide'}
modele_machia_best <- step(modele_machia_min, scope = list(lower = modele_machia_min, upper = modele_machia_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 197.7)

```{r machia-best-summary}
summary(modele_machia_best)
tbl_regression(modele_machia_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 197.7) pour pr√©dire le <i>score de machiav√©lisme (DDS)</i> et expliquant 39.9% de la variance des donn√©es.</b></center.7>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-mod-machia}
summary.aov(modele_machia_best) # R√©sum√©
```

### f) Score de psychopathie (DDS)

#### Mod√®le minimal

Cr√©ation

```{r psycho-min, results = 'hide'}
modele_psycho_min = lm(datag$Psychopathie_DDS ~ 1, data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r psycho-min-summary}
summary(modele_psycho_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{r psycho-max, results = 'hide'}
modele_psycho_max = lm(datag$Psychopathie_DDS ~ ., data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_psycho_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r psycho-max-summary}
summary(modele_psycho_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r psycho-best, results = 'hide'}
modele_psycho_best <- step(modele_psycho_min, scope = list(lower = modele_psycho_min, upper = modele_psycho_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 175.72)

```{r psycho-best-summary}
summary(modele_psycho_best)
tbl_regression(modele_psycho_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 175.72) pour pr√©dire le <i>score de psychopathie (DDS)</i> et expliquant 67.6% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-mod-psycho}
summary.aov(modele_psycho_best) # R√©sum√©
```

### g) Score de narcissisme (DDS)

#### Mod√®le minimal

Cr√©ation

```{r narci-min, results = 'hide'}
modele_narci_min = lm(datag$Narcissisme_DDS ~ 1, data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r narci-min-summary}
summary(modele_narci_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{r narci-max, results = 'hide'}
modele_narci_max = lm(datag$Narcissisme_DDS ~ ., data = datas)  # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_narci_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r narci-max-summary}
summary(modele_narci_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r narci-best, results = 'hide'}
modele_narci_best <- step(modele_narci_min, scope = list(lower = modele_narci_min, upper = modele_narci_max), data = datag, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 192.07)

```{r narci-best-summary}
summary(modele_narci_best)
tbl_regression(modele_narci_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 192.07) pour pr√©dire le <i>narcissisme (DDS)</i> et expliquant 67.47% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-mod-narci}
summary.aov(modele_narci_best) # R√©sum√©
```

### h) Niveau d'arousal (ADCL)

#### Mod√®le minimal

Cr√©ation

```{r arous-min, results = 'hide'}
modele_arous_min = lm(datag$Excitation_ADCL ~ 1, data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r arous-min-summary}
summary(modele_arous_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{r arous-max, results = 'hide'}
modele_arous_max = lm(datag$Excitation_ADCL ~ ., data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_arous_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r arous-max-summary}
summary(modele_arous_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r arous-best, results = 'hide'}
modele_arous_best <- step(modele_arous_min, scope = list(lower = modele_arous_min, upper = modele_arous_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 149.9)

```{r arous-best-summary}
summary(modele_arous_best)
tbl_regression(modele_arous_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 149.9) pour pr√©dire le <i>niveau d'arousal (ADCL)</i> et expliquant 37.4% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-mod-arous}
summary.aov(modele_arous_best) # R√©sum√©
```

## 7. Indices non-verbaux pertinents et scores cibl√©s

Ces scores √©tant des variables qualitatives discr√®tes, on effectue des r√©gressions lin√©aires multiples.

### a) Pr√©paration des donn√©es

```{r data-ind-pert}

datap <- data[,c('Sexe', 'Condition', 'Bas_visage', 'Haut_visage', 'Yeux', 'Bras', 'Mains', 'Jambes', 'Temps_P1_P2', 'Haut_visage2', 'Buste2', 'Jambes2', 'Pas_P2_Cible', 'EAFF_BES', 'Ecog_BES', 'ContSc_BES', 'Machiavelisme_DDS', 'Psychopathie_DDS', 'Narcissisme_DDS', 'Excitation_ADCL')] # Conserver les indices pertinents et les scores cibles
datap <- copy_labels(datap, data) # Copie des √©tiquettes
```

### b) Mouvements du bas du visage √† l'arr√™t 1

#### Recherche du meilleur mod√®le

```{r ind-pert-basvis1-min-max}
modele_basvis1_min = lm(datap$Bas_visage ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_basvis1_max = lm(datap$Bas_visage ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$EAFF_BES + datap$ContSc_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Excitation_ADCL + datap$Narcissisme_DDS, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_basvis1_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r ind-pert-basvis1-best, results = 'hide'}
modele_basvis1_best <- step(modele_basvis1_min, scope = list(lower = modele_basvis1_min, upper = modele_basvis1_max), data = datap, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_basvis1_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 111.63)

```{r basvis1-summary}
tbl_regression(modele_basvis1_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 111.63) pour pr√©dire le <i>nombre de mouvements du bas du visage √† l'arr√™t 1</i> et expliquant 34.04% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

### c) Mouvements du haut du visage √† l'arr√™t 1

#### Recherche du meilleur mod√®le

```{r ind-pert-hautvis1-min-max}
modele_hautvis1_min = lm(datap$Haut_visage ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_hautvis1_max = lm(datap$Haut_visage ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$ContSc_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression
summary(modele_hautvis1_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r ind-pert-hautvis1-best, results = 'hide'}
modele_hautvis1_best <- step(modele_hautvis1_min, scope = list(lower = modele_hautvis1_min, upper = modele_hautvis1_max), data = datap, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_hautvis1_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 5.25)

```{r hautvis1-summary}
tbl_regression(modele_hautvis1_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 5.25) pour pr√©dire le <i>nombre de mouvements du haut du visage √† l'arr√™t 1</i> et expliquant 6.8% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

### d) Mouvements des yeux √† l'arr√™t 1

#### Recherche du meilleur mod√®le

```{r ind-pert-yeux1-min-max}
modele_yeux1_min = lm(datap$Yeux ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_yeux1_max = lm(datap$Yeux ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$ContSc_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Excitation_ADCL + datap$Narcissisme_DDS, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_yeux1_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r ind-pert-yeux1-best, results = 'hide'}
modele_yeux1_best <- step(modele_yeux1_min, scope = list(lower = modele_yeux1_min, upper = modele_yeux1_max), data = datap, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_yeux1_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 140.05)

```{r yeux1-summary}
tbl_regression(modele_yeux1_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 140.05) pour pr√©dire le <i>nombre de mouvements des yeux √† l'arr√™t 1</i> et expliquant 36.88% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

### e) Mouvements des bras √† l'arr√™t 1

#### Recherche du meilleur mod√®le

```{r ind-pert-bras1-min-max}
modele_bras1_min = lm(datap$Bras ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_bras1_max = lm(datap$Bras ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$ContSc_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_bras1_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r ind-pert-bras1-best, results = 'hide'}
modele_bras1_best <- step(modele_bras1_min, scope = list(lower = modele_bras1_min, upper = modele_bras1_max), data = datap, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_bras1_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 52.9)

```{r bras1-summary}
tbl_regression(modele_bras1_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 52.9) pour pr√©dire le <i>nombre de mouvements des bras √† l'arr√™t 1</i> et expliquant 33.81% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

### f) Mouvements des mains √† l'arr√™t 1

#### Recherche du meilleur mod√®le

```{r ind-pert-mains1-min-max}
modele_mains1_min = lm(datap$Mains ~ 1, data = datap)  # Cr√©ation du mod√®le de r√©gression minimal
modele_mains1_max = lm(datap$Mains ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$ContSc_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_mains1_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r ind-pert-mains1-best, results = 'hide'}
modele_mains1_best <- step(modele_mains1_min, scope = list(lower = modele_mains1_min, upper = modele_mains1_max), data = datap, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_mains1_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 97.97)

```{r mains1-summary}
tbl_regression(modele_mains1_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 97.97) pour pr√©dire le <i>nombre de mouvements des mains √† l'arr√™t 1</i> et expliquant 14.25% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

### g) Mouvements des jambes √† l'arr√™t 1

#### Recherche du meilleur mod√®le

```{r ind-pert-jambes1-min-max}
modele_jambes1_min = lm(datap$Jambes ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_jambes1_max = lm(datap$Jambes ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$ContSc_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_jambes1_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r ind-pert-jambes1-best, results = 'hide'}
modele_jambes1_best <- step(modele_jambes1_min, scope = list(lower = modele_jambes1_min, upper = modele_jambes1_max), data = datap, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_jambes1_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 162.79)

```{r jambes1-summary}
tbl_regression(modele_jambes1_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 162.79) pour pr√©dire le <i>nombre de mouvements des jambes √† l'arr√™t 1</i> et expliquant 39.01% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```
#### Normalit√© des r√©sidus 
```{r jambes1-resi}
shapiro.test(modele_jambes1_best$residuals)
```

La p-valeur est non-significative (0.07739) : on ne rejette pas H0, les r√©sidus sont gaussiens et respectent les hypoth√®ses du mod√®le lin√©aire multiple.

### h) Temps entre l'arr√™t 1 et l'arr√™t 2

#### Recherche du meilleur mod√®le

```{r ind-pert-tempsp1p2-min-max}
modele_tempsp1p2_min = lm(datap$Temps_P1_P2 ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_tempsp1p2_max = lm(datap$Temps_P1_P2 ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$ContSc_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_tempsp1p2_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r ind-pert-tempsp1p2-best, results = 'hide'}
modele_tempsp1p2_best <- step(modele_tempsp1p2_min, scope = list(lower = modele_tempsp1p2_min, upper = modele_tempsp1p2_max), data = datap, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_tempsp1p2_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 69.7)

```{r tempsp1p2-summary}
tbl_regression(modele_tempsp1p2_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 69.7) pour pr√©dire le <i>temps entre l'arr√™t 1 et l'arr√™t 2</i> et expliquant 18.69% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

### i) Mouvements du haut du visage √† l'arr√™t 2

#### Recherche du meilleur mod√®le

```{r ind-pert-hautvis2-min-max}
modele_hautvis2_min = lm(datap$Haut_visage2 ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_hautvis2_max = lm(datap$Haut_visage2 ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$ContSc_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_hautvis2_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r ind-pert-hautvis2-best, results = 'hide'}
modele_hautvis2_best <- step(modele_hautvis2_min, scope = list(lower = modele_hautvis2_min, upper = modele_hautvis2_max), data = datap, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_hautvis2_best) # R√©sum√© du mod√®le
```

### j) Mouvements du buste √† l'arr√™t 2

#### Recherche du meilleur mod√®le

```{r ind-pert-buste2-min-max}
modele_buste2_min = lm(datap$Buste2 ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_buste2_max = lm(datap$Buste2 ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$ContSc_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_buste2_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r ind-pert-buste2-best, results = 'hide'}
modele_buste2_best <- step(modele_buste2_min, scope = list(lower = modele_buste2_min, upper = modele_buste2_max), data = datap, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_buste2_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 166.56)

```{r buste2-summary}
tbl_regression(modele_buste2_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 166.56) pour pr√©dire le <i>mouvements du buste √† l'arr√™t 2</i> et expliquant 21.09% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

### k) Mouvements des jambes √† l'arr√™t 2

#### Recherche du meilleur mod√®le

```{r ind-pert-jambes2-min-max}
modele_jambes2_min = lm(datap$Jambes2 ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_jambes2_max = lm(datap$Jambes2 ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$ContSc_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_jambes2_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r ind-pert-jambes2-best, results = 'hide'}
modele_jambes2_best <- step(modele_jambes2_min, scope = list(lower = modele_jambes2_min, upper = modele_jambes2_max), data = datap, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_jambes2_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 203.9)

```{r jambes2-summary}
tbl_regression(modele_jambes2_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 203.9) pour pr√©dire le <i>mouvements des jambes √† l'arr√™t 2</i> et expliquant 36.13% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

#### Normalit√© des r√©sidus 
```{r jambes2-resi}
shapiro.test(modele_jambes2_best$residuals)
```

La p-valeur est non-significative (0.01899) : on rejette H0, les r√©sidus ne sont pas gaussiens.

### l) Nombre de pas entre l'arr√™t 2 et la cible

#### Recherche du meilleur mod√®le

```{r ind-pert-pasp2cible-min-max}
modele_pasp2cible_min = lm(datap$Pas_P2_Cible ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_pasp2cible_max = lm(datap$Pas_P2_Cible ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$ContSc_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_pasp2cible_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{r ind-pert-pasp2cible-best, results = 'hide'}
modele_pasp2cible_best <- step(modele_pasp2cible_min, scope = list(lower = modele_pasp2cible_min, upper = modele_pasp2cible_max), data = datap, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_pasp2cible_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 96.98)

```{r pasp2cible-summary}
tbl_regression(modele_pasp2cible_best,
               estimate_fun = partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  bold_p() %>% # p-valeurs significatives en gras  
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 96.98) pour pr√©dire le <i>nombre de pas entre l'arr√™t 2 et la cible</i> et expliquant 8.14% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

## 8. R√©gressions mixtes

#### Pr√©cisions

En plus des effets fixes √©tudi√©s dans les mod√®les de r√©gression lin√©aire, les r√©gressions mixtes prennent en consid√©ration les effets al√©atoires, afin d'observer les corr√©lations entre les variables.

Ce type de r√©gression produit :

-   Les p-valeurs des effets fixes.

-   La valeur W du test de Shapiro-Wilk (test de Normalit√©) et la p-valeur associ√©e (on rejette la normalit√© quand la p-valeur \> .05, donc non significative).

#### Pr√©paration des donn√©es

```{r lmer-prep, results = 'hide'}
datam <- datag[,-c(32:34,40:46,48:55)] # Variables pertinentes (m√©moire)
datam <- cbind.data.frame(data$Code, datam) # Ajout du code sujet
names(datam)[names(datam) == 'data$Code'] <- 'Code' # Renommer la colonne du code sujet
datam$Code <-  factor(datam$Code) # Factorisation 
datam$Condition <- factor(datam$Condition, labels = c("Agression", "T√©l√©phone") ) # Factorisation
datam$Sexe <- factor(datam$Sexe, # Factorisation
                    labels = c("F√©minin", "Masculin"))
datam <- datam %>% relocate(Code, .after = Excitation_ADCL) # D√©placement √† la fin du tableau
datam <- datam %>% relocate(Condition, .after = Excitation_ADCL) # D√©placement √† la fin du tableau
datam <- datam %>% relocate(Sexe, .after = Excitation_ADCL) # D√©placement √† la fin du tableau
datam <- datam %>% relocate(Age, .after = Excitation_ADCL) # D√©placement √† la fin du tableau
```

#### Tous les mod√®les

```{r lmer-boucle-mod}
lmer_all_mod <- list() # Cr√©ation d'une liste pour stocker les mod√®les
for (i in 1:34) # On tourne sur les 34 premi√®res colonnes (toutes les variables √©tudi√©es)
{
  var <- (datam)[,i] # Variable interm√©diaire
  lmer_all_mod$names[[i]] <- colnames(datam)[i] # Nom des colonnes
  mod_REML <- lmer(var ~ Sexe * Age + (1|Condition), data = datam) # Mod√®les
  lmer_all_mod$shap[[i]] = shapiro.test(summary(update(mod_REML, REML = FALSE))$residuals) # R√©sidus du test de Shapiro
  lmer_all_mod$pval[[i]] = Anova(update(mod_REML, REML = FALSE), type = "III")  # P-valeurs de l'Anova
} 
```

#### R√©sultats

Stockage

```{r lmer-boucle-res-mod}
lmer_results <- function(lmer_all_mod){ # Fonction d'affichage
    list_model <- attributes(lmer_all_mod$pval[[1]])$row.names # Nom des colonnes
    tmp <- matrix(0, ncol = length(list_model) + 2, nrow = length(lmer_all_mod$names) ,dimnames = list(lmer_all_mod$names, c(paste(list_model[(seq(list_model))], "(p-val)"),"W", "p-val (W)"))) # Valeurs √† afficher
    for(i in seq(length(lmer_all_mod$pval))){
        for (j in seq(length(list_model))){
            tmp[i,j] <- lmer_all_mod$pval[[i]][[3]][j] # P-valeurs des effets fixes
        }
         tmp[i,j+1] <- lmer_all_mod$shap[[i]]$statistic # Statistique de test de Shapiro
         tmp[i,j+2] <- lmer_all_mod$shap[[i]]$p.value # P-valeurs du test de Shapiro
    }
    return(tmp)
    assign(paste0(lmer_all_mod,"lmer_results"),as.data.frame(tmp), envir = parent.frame()) # Tableau
}
```

Affichage

```{r lmer-boucle-print-mod}
#labels_dt = data.frame(var_label(datam[1:32], unlist = TRUE))
#labels_list = list(labels_dt[c(1:30),2])
lmer_pval <- data.frame(round(lmer_results(lmer_all_mod),5)) # Appliquer la fonction √† nos mod√®les et arrondir les valeurs
lmer_pval %>%
  kbl(caption = "<b>R√©gressions mixtes.</b>", # L√©gende
      col.names = c("p-valeur Constante", "p-valeur Sexe", "p-valeur Age", "p-valeur Sexe * Age", "W", "p-valeur W")) %>% # Nom des colonnes
      #row.names = c("Nombre de mouvements du haut du visage √† l'arr√™t 1", "Nombre de mouvements du bas du visage √† l'arr√™t 1", "Nombre de clignements des yeux √† l'arr√™t 1","Nombre de mouvements des yeux √† l'arr√™t 1", "Nombre de mouvements de la t√™te √† l'arr√™t 1", "Nombre de mouvements du buste √† l'arr√™t 1","Nombre de mouvements des bras √† l'arr√™t 1", "Nombre de mouvements des mains √† l'arr√™t 1", "Nombre de mouvements des jambes √† l'arr√™t 1","Nombre de mouvements des pieds √† l'arr√™t 1", "Nombre de self-adaptators √† l'arr√™t 1","Nombre de pas entre l'arr√™t 1 et l'arr√™t 2","Temps entre l'arr√™t 1 et l'arr√™t 2","Nombre de mouvements du haut du visage √† l'arr√™t 2","Nombre de mouvements du bas du visage √† l'arr√™t 2","Nombre de clignements des yeux √† l'arr√™t 2","Nombre de mouvements des yeux √† l'arr√™t 2","Nombre de mouvements de la t√™te √† l'arr√™t 2","Nombre de mouvements du buste √† l'arr√™t 2","Nombre de mouvements des bras √† l'arr√™t 2","Nombre de mouvements des mains √† l'arr√™t 2", "Nombre de mouvements des jambes √† l'arr√™t 2","Nombre de mouvements des pieds √† l'arr√™t 2", "Nombre de self-adaptators √† l'arr√™t 2", "Nombre de pas entre l'arr√™t 2 et la cible","Temps entre l'arr√™t 2 et la cible","Score d'empathie affective (BES)","Score d'empathie cognitive (BES)","Score de machiav√©lisme (DDS)","Score de psychopathie (DDS)", "Score de narcissisme (DDS)", "Score √† la QPM38 (Matrices de Raven)","Centile √† la QPM38 (Matrices de Raven)", "Niveau d'arousal (ADCL)")) %>% # Nom des colonnes
  kable_material(full_width = F) %>% # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%", height = "300px") # Barres de d√©filement
```

# V -- Graphiques

## 1. <i>Condition</i> et scores cibles

### a) Score d'empathie affective (BES)

```{r graph-cond-eaff}
ggboxplot(data, x = "Condition", y = "EAFF_BES", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Score d'empathie affective (BES)",
          title = "Score d'empathie affective (BES) selon la condition.")
```

### b) Score d'empathie cognitive (BES)

```{r graph-cond-ecog}
ggboxplot(data, x = "Condition", y = "Ecog_BES", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Score d'empathie cognitive (BES)",
          title = "Score d'empathie cognitive (BES) selon la condition.")
```

### c) Score de machiav√©lisme (DDS)

```{r graph-cond-machia}
ggboxplot(data, x = "Condition", y = "Machiavelisme_DDS", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Score de machiav√©lisme (DDS)",
          title = "Score de machiav√©lisme (DDS) selon la condition.")
```

### d) Score de psychopathie (DDS)

```{r graph-cond-psycho}
ggboxplot(data, x = "Condition", y = "Psychopathie_DDS", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Score de psychopathie (DDS)",
          title = "Score de psychopathie (DDS) selon la condition.")
```

### e) Score de narcissisme (DDS)

```{r graph-cond-narci}
ggboxplot(data, x = "Condition", y = "Narcissisme_DDS", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Score de narcissisme (DDS)",
          title = "Score de narcissisme (DDS) selon la condition.")
```

### f) Niveau d'arousal (ADCL)

```{r graph-cond-arousal}
ggboxplot(data, x = "Condition", y = "Excitation_ADCL", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Niveau d'arousal (ADCL)",
          title = "Niveau d'arousal (ADCL) selon la condition.")
```

## 2. <i>Condition</i> et variables avec une corr√©lation sup√©rieure √† 40%

### a) Jambes √† l'arr√™t 2

```{r graph-cond-jambes2}
ggboxplot(data, x = "Condition", y = "Jambes2", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Nombre de mouvements des jambes",
          title = "Nombre de mouvements des jambes selon la condition.")
```

### b) Score Contagion √âmotionelle (BES)

```{r graph-cond-contsc}
ggboxplot(data, x = "Condition", y = "ContSc_BES", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Score de contagion √©motionnelle (BES)",
          title = "Score de contagion √©motionnelle (BES) selon la condition.")
```
