---
title: "Analyse des donn√©es comportementales"
subtitle: "M√©moire ‚Äì Master 1 Sciences Cognitives"
author: "<i>M√©lody Hannoah, Marianne Mortier-Mourzelas & Astrid Th√©bault Guiochon</i>"
output: 
  html_document:
    toc: true # table of content true
    toc_depth: 3  # nombre de niveaux
    toc_float: true
      #collapsed: false # montrer tous les niveaux de titre
    # number_sections: true  # num√©roter les titres
    theme: lumen #united (orange mais le gras ne se voit pas)
    highlight: kate #th√®me du code
tags: [knitr, servr]
---

```{r setup, include = FALSE}
options(knitr.kable.NA = '', knitr.table.format = "html")
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

# I -- Chargement

## 1. Librairies

### a) Pr√©cisions

üí° *On installe une seule fois sur son ordi les librairies avec :*

    install.packages("NomDeLaLibrairie")

*On appelle au d√©but du script √† chaque fois avec :*

    library(NomDeLaLibrairie)

### b) Installation

‚ö†Ô∏è N√©cessaire uniquement la premi√®re fois qu'on ex√©cute le script.

üí° *Ajouter `{CRAN}` apr√®s les \`\`\`*

    tinytex::install_tinytex()
    install.packages("corrplot")
    install.packages("dplyr")
    install.packages("expss")
    install.packages("ggpubr")
    install.packages("gtsummary")  
    install.packages("Hmisc")
    install.packages("kableExtra")
    install.packages("knitr")
    install.packages("labelled")
    install.packages("magrittr")
    install.packages("psych")
    install.packages("purrr")
    install.packages("RCurl")
    install.packages("skimr")
    install.packages("sjlabelled")
    install.packages("sjPlot")
    install.packages("tidyverse")

### c) D√©claration

On d√©clare les librairies qu'on utilise et permettent d'appeler des fonctions particuli√®res.

```{r libraries}
library(corrplot)
library(dplyr)
library(expss)
library(ggpubr)
library(gtsummary)  
library(Hmisc)
library(kableExtra)
library(knitr)
library(labelled)
library(magrittr)
library(psych)
library(purrr)
library(RCurl)
library(skimr)
library(sjlabelled)
library(sjPlot)
library(tidyverse)
```

## 2. R√©pertoire de travail

‚ö†Ô∏è R√©pertoire par d√©faut : MacBook d'As.

üí° *√Ä adapter selon l'user*

```{r directory}
# setwd("/Users/astridguiochon/Library/CloudStorage/OneDrive-Personnel/Documents/M1/S2 SCo/Criminalistique/Analyse/Stats")
```

## 3. Ouverture du fichier

üí° *Si jamais il importe les donn√©es en un gros bloc au lieu d'un tableau, remplacer le sep = ";" par sep = "," (d√©pend de la version d'Excel et comment il exporte en .csv).*

```{r file}
git_file <- 'https://raw.githubusercontent.com/astridgcn/R-Behavioral-Analysis/main/Comptage.csv'
data = read.csv(file = git_file, sep = ";", check.names = F, header = TRUE) 
```

## 4. Pr√©paration des donn√©es

Transformation des donn√©es dans les bons formats

```{r factorize}
data$Condition <- factor(data$Condition, labels = c("Agression", "T√©l√©phone") )
data$Sexe <- factor(data$Sexe, 
                    labels = c("F√©minin", "Masculin"))
```

Filtrage des donn√©es vides

```{r filter}
data <- filter(data, data$Total_SM > 0)
```

√âtiquette de noms des donn√©es

```{r labels}
#apply_labels
var_label(data) <- list(Sexe = "Sexe",
                         Condition = "Condition",
                         Haut_visage = "Nombre de mouvements du haut du visage √† l'arr√™t 1",
                         Bas_visage = "Nombre de mouvements du bas du visage √† l'arr√™t 1",
                         Clignements = "Nombre de clignements des yeux √† l'arr√™t 1",
                         Yeux = "Nombre de mouvements des yeux √† l'arr√™t 1",
                         Tete = "Nombre de mouvements de la t√™te √† l'arr√™t 1",
                         Buste = "Nombre de mouvements du buste √† l'arr√™t 1",
                         Bras = "Nombre de mouvements des bras √† l'arr√™t 1",
                         Mains = "Nombre de mouvements des mains √† l'arr√™t 1",
                         Jambes = "Nombre de mouvements des jambes √† l'arr√™t 1",
                         Pieds = "Nombre de mouvements des pieds √† l'arr√™t 1",
                         Self_Adaptators = "Nombre de self-adaptators √† l'arr√™t 1",
                         Pas_P1_P2 = "Nombre de pas entre l'arr√™t 1 et l'arr√™t 2",
                         Temps_P1_P2 = "Temps entre l'arr√™t 1 et l'arr√™t 2",
                         Vitesse_P1_P2 = "Vitesse entre l'arr√™t 1 et l'arr√™t 2",
                           
                         Haut_visage2 = "Nombre de mouvements du haut du visage √† l'arr√™t 2",
                         Bas_visage2 = "Nombre de mouvements du bas du visage √† l'arr√™t 2",
                         Clignements2 = "Nombre de clignements des yeux √† l'arr√™t 2",
                         Yeux2 = "Nombre de mouvements des yeux √† l'arr√™t 2",
                         Tete2 = "Nombre de mouvements de la t√™te √† l'arr√™t 2",
                         Buste2 = "Nombre de mouvements du buste √† l'arr√™t 2",
                         Bras2 = "Nombre de mouvements des bras √† l'arr√™t 2",
                         Mains2 = "Nombre de mouvements des mains √† l'arr√™t 2",
                         Jambes2 = "Nombre de mouvements des jambes √† l'arr√™t 2",
                         Pieds2 = "Nombre de mouvements des pieds √† l'arr√™t 2",
                         Self_Adaptators2 = "Nombre de self-adaptators √† l'arr√™t 2",
                         Pas_P2_Cible = "Nombre de pas entre l'arr√™t 2 et la cible",
                         Temps_P2_Cible = "Temps entre l'arr√™t 2 et la cible",
                         Vitesse_P2_Cible = "Vitesse entre l'arr√™t 2 et la cible",
                         
                         EAFF_BES = "Score d'empathie affective (BES)",
                         Ecog_BES = "Score d'empathie cognitive (BES)",
                         CogSc_BES = "Score d'aspects cognitifs (BES)",
                         ContSc_BES = "Score de contagion √©motionnelle (BES)",
                         DecoSc_BES = "Score de d√©connexion √©motionnelle (BES)",
                         Total_BES = "Score total √† la BES (√âchelle d'Empathie)",
                         
                         Machiavelisme_DDS = "Score de machiav√©lisme (DDS)",
                         Psychopathie_DDS = "Score de psychopathie (DDS)",
                         Narcissisme_DDS = "Score de machiav√©lisme (DDS)",
                         Total_DDS = "Score total √† la DDS (Triade Sombre)",
                         
                         R_QI = "Score de r√©ponses √† la QPM38 (Matrices de Raven)",
                         QPM38_QI = "Score √† la QPM38 (Matrices de Raven)",
                         Centile_QI = "Score √† la QPM38 (Matrices de Raven)",
                         
                         Activation_Generale_Trait_ADCL = "Score d'activation g√©n√©rale trait (ADCL)",
                         Serenite_Trait_ADCL = "Niveau de s√©r√©nit√© trait (ADCL)",
                         Anxiete_Trait_ADCL = "Niveau d'anxeit√© trait (ADCL)",
                         Autres_ADCL = "Autres niveaux (ADCL)",
                         Activation_Etat_ADCL = "Score d'activation g√©n√©rale √©tat (ADCL)",
                         Serenite_Etat_ADCL = "Niveau de s√©r√©nit√© √©tat (ADCL)",
                         Fatigue_Etat_ADCL = "Niveau de fatigue √©tat (ADCL)",
                         Excitation_ADCL = "Niveau d'arousal (ADCL)",
                         
                         Extraversion_BFI = "Score d'extraversion (BFI)",
                         Agreabilite_BFI = "Score d'agr√©abilit√© (BFI)",
                         Conscienseuxse_BFI = "Score de conscienciosit√© (BFI)",
                         Nevrotisme_BFI = "Score de n√©vrotisme (BFI)",
                         Ouverture_Esprit_BFI = "Score d'ouverture d'esprit (BFI)",
                         
                         Comedie_SM = "Score de com√©die (SM)",
                         Extraversion_SM = "Score d'extraversion (SM)",
                         PresDeSoi_SM = "Score de pr√©sentation de soi (SM)",
                         Total_SM = "Score total SM (Self-Monitoring)") # Nom des variables
```

## 5. Affichage des donn√©es

Affichage en un tableau

```{r print-data}
dt_Data <- data[1:35,1:62]
dt_Data %>%
  kbl(caption = "<b>Pr√©sentation du jeu de donn√©es.</b>") %>% # L√©gende
  kable_material(full_width = F) %>% # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%", height = "300px") # Barres de d√©filement
```

# II -- Statistiques descriptives

## 1. Globalit√©

R√©sum√© statistique des donn√©es

```{r print-summary-data}
summary(data[,! names(data) %in% c("Code")]) %>%
  kbl(caption = "<b>R√©sum√© statistique du jeu de donn√©es.</b>") %>%  # L√©gende
  kable_material(full_width = F) %>%  # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%") # Barre de d√©filement
```

¬†

R√©sum√© statistique des donn√©es selon le <i>Sexe</i>

```{r summary-data-sex}
#summary(data[,-1]) %>% split(.$Sexe) %>% map(summary)
#describeBy(data[,-1], data$Sexe)
dt_Sum_data_sex <- data[,] %>%
  group_by(Sexe) %>%
  skim() 

dt_Sum_data_sex <- dt_Sum_data_sex[-c(1,2),c(2:3,9:10,12:14,16)]
colnames(dt_Sum_data_sex) <- c("Variable", "Sexe", "Moyenne", "√âcart-Type", "Q1", "M√©diane", "Q3", "Histogramme")
dt_Sum_data_sex %>%
  kbl(caption = "<b>R√©sum√© statistique du jeu de donn√©es selon le <i>Sexe</i>.</b>") %>%  # L√©gende
  kable_material(full_width = F) %>%  # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%", height = "400px") # Barres de d√©filement
```

¬†

R√©sum√© statistique des donn√©es selon la <i>Condition</i>

```{r summary-data-cond}
dt_Sum_data_cond <- data[,-1] %>%
  group_by(Condition) %>%
  skim()

dt_Sum_data_cond <- dt_Sum_data_cond[-c(1,2),c(2:3,9:10,12:14,16)]
colnames(dt_Sum_data_cond) <- c("Variable", "Condition", "Moyenne", "√âcart-Type", "Q1", "M√©diane", "Q3", "Histogramme")
dt_Sum_data_sex%>%
  kbl(caption = "<b>R√©sum√© statistique du jeu de donn√©es selon la <i>Condition</i>.</b>") %>%  # L√©gende
  kable_material(full_width = F) %>%  # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%", height = "400px") # Barres de d√©filement
```

¬†

üí° *R√©sume les statistiques de base de chaque variable :*

-   **Minimum** *: plus petite valeur observ√©e.*

-   **Q1** *(1er quantile) : au moins de 25% de l'√©chantillon sous cette valeur.*

-   **M√©diane** *(2√®me quantile) : au moins de 50% de l'√©chantillon sous cette valeur.*

-   **Moyenne**.

-   **Mode** *: valeur observ√©e avec le plus grand effectif (la plus r√©pandue).*

-   **Q3** *(3√®me quantile) : au moins de 75% de l'√©chantillon sous cette valeur.*

-   **Maximum** *: plus grande valeur observ√©e.*

-   **Valeurs manquantes** *: g√©n√©ralement "NA", mais remplac√© par des cases vierges ici.*

## 2. Par variable

### a) √Çge (sexe et condition)

Calcul de la variance totale

```{r var-tot}
var_age <- data.frame("Total", "", var(data$Age)) # Cr√©ation du tableau
colnames(var_age) <- c("Sexe", "Condition", "Variance") # Nom des colonnes
```

Calcul de la variance selon le sexe et la condition

```{r var-age}
Age_var <- aggregate (x = data$Age,
                      by = list(data$Sexe, data$Condition),
                      FUN = var
                      ) # Variance de l'√¢ge par sexe et condition
colnames(Age_var) <- c("Sexe", "Condition", "Variance") # Nom des colonnes
```

Tableau regroupant le tout

```{r tab-var}
Age_var <- rbind (Age_var, var_age) # Fusion des 2 tableaux
```

Affichage et mise en forme du tableau

```{r print-tab-var}
dt_Age_var <- Age_var[1:5,1:3] # S√©lection du tableau
dt_Age_var %>%
  kbl(caption = "<center><b>Variance de l'√¢ge selon le sexe et la condition.</b></center>") %>% # L√©gende
  kable_material(full_width = F) %>% # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) # Options de surlignage et rayures
```

### b) Indices comportementaux

Calcul de la variance et tableau

```{r var-ind}
Ind_var <- data.frame(data[,5:32] %>% summarise_if(is.numeric, var)) # Tableau r√©sum√© statistique
rownames(Ind_var) <- c("Variance") # Nom des lignes
```

Affichage et mise en forme du tableau

```{r print-var-ind}
dt_Ind_var <- Ind_var[1:28] # S√©lection du tableau
dt_Ind_var %>%
  kbl(caption = "<b>Variance des indices comportementaux.</b>") %>% # L√©gende
  kable_material(full_width = F) %>% # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%") # Barre de d√©filement
```

### c) Scores aux tests de personnalit√©

Calcul de la variance et tableau

```{r var-tests}
Tests_var <- data.frame(data[,33:62] %>% summarise_if(is.numeric, var)) # Tableau r√©sum√© statistique
rownames(Tests_var) <- c("Variance") # Nom des lignes
```

Affichage et mise en forme du tableau

```{r print-var-tests}
dt_Tests_var <- Tests_var[1:30] # S√©lection du tableau
dt_Tests_var %>%
  kbl(caption = "<b>Variance des scores aux tests de personnalit√©.</b>") %>% # L√©gende
  kable_material(full_width = F) %>% # Taille et style
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%") # Barre de d√©filement
```

Suppression des donn√©es aberrantes

```{r outliers}
datao <- data[,5:55] # Copie du dataframe
datao <- copy_labels(datao, data) # Copie des √©tiquettes

# Fonction de rep√©rage des valeurs aberrantes
find_outliers <- function(x) { 
  Q1 <- quantile(x, probs = .25) # Premier quantile (Q1)
  Q3 <- quantile(x, probs = .75) # Trois√®me quantile (Q3)
  IQR = Q3-Q1 # √âcart inter-quantile (Q3 - Q1)
  min = Q1 - (IQR * 1.5) # Borne inf√©rieure
  max = Q3 + (IQR*  1.5) # Borne sup√©rieure
  x > max | x < min # Si une valeur n'est pas dans l'intervalle, elle est un outlier / valeur aberrante
} 
 
# Fonction de suppression des valeurs aberrantes
remove_outliers <- function(df, cols = names(df)) { 
  for (col in cols) { 
    df <- df[!find_outliers(df[[col]]),] # Conserve les donn√©es pas aberrantes
  } 
}

# Appel de la fonction sur data et stockage dans un nouveau tableau
remove_outliers(datao, as.vector(names(datao))) 

```

# III -- Statistiques inf√©rentielles

## 1. Pr√©paration des donn√©es

Transformation des donn√©es dans les bons formats

```{r binarize}
datag <- data # Copie du jeu de donn√©es
datag <- copy_labels(data,datag) # Copie des √©tiquettes
datag$Condition <- ifelse(data$Condition == "Agression", 1, 0) # Remplacement des A par 1 et le reste (T) par 0
datag$Sexe <- ifelse(data$Sexe == "Masculin", 1, 0) # Remplacement des M par 1 et le reste (F) par 0
datag <- datag[,-c(1,43)] # Suppression du code sujet et du R de la QPM38 (qui sont li√©s lin√©airement)
```

## 2. Corr√©lations

### a) Pr√©cisions

#### Test

On utilise un **test de rang de Kendall** car il ne d√©pend pas de la distribution des donn√©es donc on n'a pas besoin de v√©rifier qu'elles soient Gaussiens (suivent une Loi Normale).

#### Utilisation

    cor.test(x, y, method="kendall") 

On peut stocker le r√©sultat dans une variable.

üí° *Mettre as.numeric(x) et pareil pour y vu que ce sont des variables √† facteurs / niveaux.*

    cor.V1.V2 <- cor.test(as.numeric(data$v1), as.numeric(data$V2), method="kendall")

#### Valeurs

-   **\\(z\\)** *= statistique de test*.
-   **\\(p-value\\)** *= p-valeur du test de corr√©lation (niveau d'erreur du test, plus elle est petite, mieux c'est "significatif" g√©n√©ralement quand elle est sous 0.05 ou 0.01).*
-   **\\(\\tau\\) (tau)** *= coefficient de corr√©lation.*

#### Interpr√©tation

-   Plus [tau]{.underline} est proche de **1** plus la relation **positive** est forte. Ils varient dans le [**m√™me** sens]{.underline}, si l'un augmente / diminue alors l'autre aussi.
-   Plus [tau]{.underline} est proche de **-1** plus la relation **n√©gative** est forte. Ils varient dans des [sens **oppos√©s**]{.underline}, quand l'un augmente / diminue, l'autre diminue / augmente.

### b) Matrices de corr√©lation

#### Sans les p-valeurs

```{r cor-matrix}
cor_matrix <- round(cor(datag, method = c("pearson", "kendall", "spearman")), 3) # Calcul des corr√©lations
dt_Cor_matrix <- data.frame(cor_matrix) # Transformation en tableau
```

Affichage et mise en forme du tableau

```{r print-cor-matrix}
dt_Cor_matrix %>%
  mutate_all(~ cell_spec(.x, color = case_when(.x == 1 ~ "white",
                                              .x <= -0.4 ~ "#A10A2E",
                                              .x <= -0.25 ~ "#EE80A7",
                                              .x >= 0.25 ~ "#043F6F",
                                              .x >= 0.4 ~ "#80CBEE",
                                              is.na(.x) ~ "white",
                                              TRUE ~ "lightgrey"))) %>% # Conditions de couleurs
  kable(escape = F, 
        caption = "<b>Corr√©lations entre toutes les variables.</b>") %>% # L√©gende
  column_spec(1, bold = T) %>% # Premi√®re colonne en gras
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%", height = "350px") # Barres de d√©filement
```

¬†

#### Avec les p-valeurs

```{r cor-matrix-p}
cor_matrix_p <- rcorr(as.matrix(datag)) # Matrice de corr√©lation avec les p-valeurs
```

Transformer en tableau

```{r dt-cor-matrix-p}
CorMatrix <- function(cormat, pmat) { # Fonction de transformation de la matrice en tableau
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut], # cormat : matrice des coefficients de corr√©lation
    p = pmat[ut] # pmat : matrice des p-valeurs
    )
  }
```

Ordonner et arrondir les donn√©es

```{r proc-cor-matrix-p}
dt_Cor_matrix_p <- CorMatrix(cor_matrix_p$r, cor_matrix_p$P) # Application de la fonction de trnasformation en tableau
dt_Cor_matrix_p[is.na(dt_Cor_matrix_p)] <- 0 # Remplacement des cases vides par des 0 
dt_Cor_matrix_p$cor <- round(dt_Cor_matrix_p$cor,3) # Arrondi des coefficients de corr√©lations √† 3 d√©cimales
dt_Cor_matrix_p$p <- round(dt_Cor_matrix_p$p,4) # Arrondi des p-valeurs √† 4 d√©cimales
dt_Cor_matrix_p <- dt_Cor_matrix_p[order(dt_Cor_matrix_p$p),] # Rangement croissant des valeurs selon les p-valeurs
```

Affichage et mise en forme du tableau ¬†\
<i>Les corr√©lations √©lev√©es entre les scores des √©chelles et leurs totaux sont normales et permettent de v√©rifier la coh√©rence des donn√©es. De m√™me pour certaines valeurs au sein de la BES.</i>

```{r print-cor-matrix-p}
dt_Cor_matrix_p %>%
  mutate(
    cor = cell_spec(cor, color = case_when(cor == 1 ~ "white",
                                           cor <= -0.4 ~ "#A10A2E",
                                           cor <= -0.25 ~ "#EE80A7",
                                           cor >= 0.25 ~ "#043F6F",
                                           cor >= 0.4 ~ "#80CBEE",
                                           is.na(cor) ~ "white",
                                           TRUE ~ "lightgrey")),
    p = cell_spec(p, color = case_when(p > 0.1 ~ "lightgrey",
                                       p <= 0.01 ~ "#266617",
                                       p <= 0.05 ~ "#3FA329",
                                       p <= 0.1 ~ "#D5F0C9",
                                       is.na(p) ~ "white",
                                       TRUE ~ "lightgrey"))) %>% # Conditions de couleurs
  kable(escape = F, 
        caption = "<b><center>Corr√©lations entre toutes les variables et p-valeurs.</b></center>", 
        col.names = c("Variable 1", "Variable 2", "Coefficient de corr√©lation", "p-valeur")) %>% # L√©gende et noms des colonnes 
  column_spec(1, color = "white") %>% # Couleur de la premi√®re colonne (ordre des valeurs)
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%  # Options de surlignage et rayures
  scroll_box(width = "100%", height = "350px") # Barres de d√©filement
```

```{r plot-cor-matrix, echo = FALSE}
#Repr√©senter visuellement sans les p-valeurs
#corrplot(cor_matrix, type = "upper", order = "hclust", 
         #tl.col = "black", tl.srt = 90)
```

```{r plot-cor-matrix-p, echo = FALSE}
#Repr√©senter visuellement avec les p-valeurs
#corrplot(cor_matrix_p$r, type="upper", order="hclust", 
         #p.mat = cor_matrix_p$P, sig.level = 0.01, insig = "blank")
```

### c) Corr√©lation entre <i>Condition</i> et les autres variables

#### Sans les p-valeurs

```{r cor-cond}
cor_cond <- data.frame(cor(datag[ , colnames(datag) != "Condition"], datag$Condition)) # Tableau de corr√©lation entre la condition et les autres variables
colnames(cor_cond) <- "Condition" # Noms des colonnes
```

¬†

#### Filtrage des corr√©lations (\< -0.25 ou \> 0.25)

```{r filter-cor-cond}
dt_Cor_cond_filter <- cor_cond %>% # Nouveau tableau
  filter(Condition < -0.25  | Condition > 0.25 ) # Condition (plus de 25% ou moins de -25% pour les corr√©lations n√©gatives)
dt_Cor_cond_filter$Condition <- round(dt_Cor_cond_filter$Condition,3) # Arrondi des coefficients de corr√©lations √† 3 d√©cimales
```

Affichage et mise en forme du tableau

```{r dt-filter-cor-cond}
row.names(dt_Cor_cond_filter) <- c("Mouvements du haut de visage √† l'arr√™t 1", "Mouvement de jambes √† l'arr√™t 1", "Mouvements de pieds √† l'arr√™t 1", "Mouvement de jambes √† l'arr√™t 2", "Nombre de pas entre l'arr√™t 2 et la cible", "Vitesse entre l'arr√™t 2 et la cible", "Score total √† la BES (√âchelle d'Empathie)", "Score d'empathie affective (BES)", "Score ContSc (BES)") # Noms des lignes 
dt_Cor_cond_filter %>% 
  mutate(
    Condition = cell_spec(Condition, color = case_when(
                                                       Condition <= -0.4 ~ "#A10A2E",
                                                       Condition <= -0.25 ~ "#EE80A7",
                                                       Condition >= 0.4 ~ "#043F6F",
                                                       Condition >= 0.25 ~ "#80CBEE",
                                                       is.na(Condition) ~ "white",
                                                       TRUE ~ "lightgrey")))  %>% # Conditions couleurs
  kable(escape = F, 
        caption = "<center><b>Corr√©lations sup√©rieures √† 25% entre la <i>Condition</i> et les autres variables.</b></center>") %>% # L√©gende
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) # Options de surlignage et rayures
```

Repr√©senter visuellement

```{r plot-filter-cor-cond}
dt_Cor_cond_filter$Variable <- rownames(dt_Cor_cond_filter) # Ajout des noms de lignes
dt_Cor_cond_filter %>% 
  mutate(Variable = factor(Variable, levels = Variable[order(Condition)])) %>% # Rangement croissant 
  ggplot(aes(x = Variable, y = Condition)) + # Cr√©ation d'un graphique
    geom_bar(stat = "identity", 
             fill = "lightskyblue1", 
             alpha = 0.8, 
             width = 0.5) + # Options visuelles
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + # L√©gendes des abscisses √† la verticale
    ylab("Corr√©lation avec la Condition") + # Titre des ordonn√©es
    xlab("Variable") + # Titre des abscisses
    ggtitle("Corr√©lations sup√©rieures √† 25% entre la Condition et les autres variables.") # Titre
```

¬†

#### Avec les p-valeurs

```{r cor-matrix-cond-p}
pvals <- sapply(datag[-1], function(x) corr.test(x, datag$Condition)$p) # Calcul des p-valeurs
pvals <- round(pvals,4) # Arrondi des p-valeurs √† 4
rvals <- sapply(datag[-1], function(x) corr.test(x, datag$Condition)$r) # Calcul des coefficients de corr√©lation
rvals <- round(rvals,3) # Arrondi des coefficients de corr√©lation √† 3
```

Ordonner et arrondir les donn√©es

```{r proc-cor-matrix}
dt_Cor_matrix_cond_p <- data.frame(rbind(rvals, pvals)) # Cr√©ation d'un tableau avec les coefficients de corr√©lation et p-valeurs
dt_Cor_matrix_cond_p <- t(dt_Cor_matrix_cond_p) # Inversion des lignes et colonnes
dt_Cor_matrix_cond_p <- data.frame(dt_Cor_matrix_cond_p) # Tableau avec l'inversion
dt_Cor_matrix_cond_p <- dt_Cor_matrix_cond_p[order(dt_Cor_matrix_cond_p$pvals),] # Rangement croissant des valeurs selon les p-valeurs
```

Affichage et mise en forme du tableau

```{r print-cor-matrix-cond-p}
dt_Cor_matrix_cond_p %>%
  mutate(
    rvals = cell_spec(rvals, color = case_when(rvals == 1 ~ "grey",
                                               rvals <= -0.4 ~ "#A10A2E",
                                               rvals <= -0.25 ~ "#EE80A7",
                                               rvals >= 0.4 ~ "#043F6F",
                                               rvals >= 0.25 ~ "#80CBEE",
                                               is.na(rvals) ~ "white",
                                               TRUE ~ "lightgrey")),
    pvals = cell_spec(pvals, color = case_when(pvals > 0.1 ~ "grey",
                                               pvals <= 0.01 ~ "#266617",
                                               pvals <= 0.05 ~ "#3FA329",
                                               pvals <= 0.1 ~ "#D5F0C9",
                                               is.na(pvals) ~ "white",
                                               TRUE ~ "lightgrey"))) %>% # Conditions des couleurs
  kable(escape = F, 
        caption = "<b>Corr√©lations entre <i>Condition</i> et les autres variables et p-valeurs.</b>", 
        col.names = c("Coefficient de corr√©lation", "p-valeur")) %>% # L√©gende et noms des colonnes
  column_spec(1,  bold = T) %>% # Premi√®re colonne en gras
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% # Options de surlignage et rayures
  scroll_box(width = "100%", height = "350px") # Barres de d√©filement
```

# IV -- R√©gressions

## 1. Pr√©cisions

#### M√©thodes

üí° Il existe plusieurs m√©thodes, notamment :

-   Tester les mod√®les possibles un par un (mais on poss√®de 60 variables explicatives possibles).

-   M√©thode **ascendante** : partir du mod√®le le plus petit mod√®le et ajouter des variables explicatives.

-   M√©thode **descendante** : partir du mod√®le avec toutes les variables explicatives possibles et r√©duire petit √† petit.

Cr√©ation des mod√®les de r√©gression :

-   **Min** : la variable *Condition* (par exemple) s'explique par elle-m√™me.

-   **Max** : la variable *Condition* (par exemple) s'explique gr√¢ce √† toutes les autres variables.

#### Crit√®res pertinents

On utilise ensuite un crit√®re de vraisemblance pour estimer l'utilit√© du mod√®le :

-   **AIC** : Akaike Information Criterion. $$
    \begin{align}
      \tag{1}
        -2\ \ln(\widehat{L}) + 2k
    \end{align}
    $$
-   **BIC** : Bayesian Information Criterion. $$
    \begin{align}
      \tag{2}
        -2\ \ln(\widehat{L}) + k \ \ln(n)
    \end{align}
    $$

Ceux-ci doivent √™tre minimis√©s pour obtenir le meilleur mod√®le.

Autres crit√®res pertinents √† l'√©tude des mod√®les :

-   $R^2_{ajust√©}$ : coefficient mesurant l'ajustement du mod√®le aux donn√©es (et permet de comparer des mod√®les avec un nombre de variables diff√©rent car s'ajuste selon les donn√©es).

-   $D(y, \widehat\mu)$ : d√©viance (√† quel point on s'√©loigne du mod√®le parfait).

-   $\sigma$ : √©cart-type (racine de la variance) des r√©sidus (√©cart entre les donn√©es r√©elles et pr√©dires) du mod√®le.

-   **\\(p-value\\)** : p-valeur du test de corr√©lation (niveau d'erreur du test, plus elle est petite, mieux c'est "significatif" g√©n√©ralement quand elle est sous 0.05 ou 0.01).

üí° *Ces crit√®res l√† s'√©tudient lorsqu'on a obtenu / s√©lectionn√© le meilleur mod√®le possible.*

## 2. Tous les mod√®les possibles pour toutes les variables

```{r all-mod, results = 'hide'}
 # Cr√©ation de la liste de mod√®les avec +30% de R2 ajust√©
best_models = list()

# Incr√©mentation
i = 1

# Recherche des meilleurs mod√®les pour chaque variable
while (i <= length(datag)) {
#for (i in range(rangeA)) {
  print(variable.names(datag[i]))
  modele_min = lm(datag[,i] ~ 1, data = datag) # Cr√©ation du mod√®le de r√©gression minimal
  modele_max = lm(datag[,i] ~ ., data = datag) # Cr√©ation du mod√®le de r√©gression maximal
  modele_best = step(modele_min, scope = list(lower = modele_min, upper = modele_max), data = datag, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
  print(summary(modele_best)) # R√©sum√© du meilleur mod√®le
  name_mod = paste("modele_best", variable.names(datag[i]), sep = "_") # Cr√©ation du nom du mod√®le
  assign(name_mod, modele_best) # Stockage du mod√®le avec le bon nom
  adj.r = summary(modele_best)$adj.r.squared
  if (is.na(adj.r)){ # Si le R 2ajust√© est vide
    
  }
  else {
    if (adj.r >= 0.2) { # Si le R 2ajust√© sup√©rieur √† 0.2
      best_models = c(best_models, name_mod)
    }
  }
  rm(modele_min, modele_max, modele_best, name_mode) # Suppression des variables pour √©viter les erreurs
  i = i + 1 # Incr√©mentation
}
```

## 3. <i>Agression</i> et toutes les variables

Pr√©parer les donn√©es

```{r reg-prep}
datag <- datag[,! names(datag) %in% c("Code", "Total_BES", "Total_DDS", "Total_SM", "Vitesse_P1_P2", "Vitesse_P2_Cible")] # Retirer le code sujet et les totaux des tests
```

### a) R√©gression logistique multiple

#### Mod√®le minimal

Cr√©ation

```{r log-min, results = 'hide'}
modele_log_min = glm(datag$Condition ~ 1, data = datag, family = binomial) # Cr√©ation du mod√®le de r√©gression logistique multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r log-min-summary}
summary(modele_log_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

Cr√©ation

```{r log-max, results = 'hide'}
modele_log_max = glm(datag$Condition ~ ., data = datag, family = binomial) # Cr√©ation du mod√®le de r√©gression logistique multiple maximal (toutes les variables explicatives)
alias(modele_log_max) # R√©sum√© du mod√®le
summary(modele_log_max) # Autre r√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode descendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R log-best, results = 'hide'}
modele_log_best <- step(modele_log_max, data = datag, direction = "backward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le maximal (en √¥tant des variables)
```

Meilleur mod√®le (AIC = 22)

```{R log-best-summary}
summary(modele_log_best)
tbl_regression(modele_log_best, 
               #label = term_labels(modele_log_best), # Nom des lignes
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression logistique multiple le plus performant (AIC = 22) pour pr√©dire la <i>Condition</i>.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(estimate = "OR = Rapports des Chances", std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(include = c(AIC)) # Statistiques du mod√®le
```

### b) R√©gression lin√©aire multiple

#### Mod√®le minimal

Cr√©ation

```{R min, results = 'hide'}
modele_min = lm(datag$Condition ~ 1, data = datag) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal  (aucune variable explicative)
```

R√©sum√©

```{r min-summary}
summary(modele_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{R max, results = 'hide'}
modele_max = lm(Condition ~ ., data = datag) # # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_max) # R√©sum√© du mod√®le
summary(modele_max) # Autre r√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R best, results = 'hide'}
modele_best <- step(modele_min, scope = list(lower = modele_min, upper = modele_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = -596.59)

```{R best-summary}
tbl_regression(modele_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs) %>%
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = -596.59) pour pr√©dire la <i>Condition</i>.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") # Niveau de significativit√©
```

## 4. <i>Condition</i> et variables avec une corr√©lation sup√©rieure √† 25%

### a) R√©gression logistique multiple

#### Mod√®le minimal

Cr√©ation

```{r log-sel-min, results = 'hide'}
modele_log_sel_min = glm(datag$Condition ~ 1, data = datag, family = binomial) # Cr√©ation du mod√®le de r√©gression logistique multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r log-sel-min-summary}
summary(modele_log_sel_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

Cr√©ation

```{r log-sel-max, results = 'hide'}
modele_log_sel_max = glm(datag$Condition ~  Haut_visage + Jambes + Pieds + Pas_P2_Cible + EAFF_BES + ContSc_BES, data = datag, family = binomial) # Cr√©ation du mod√®le de r√©gression logistique multiple maximal (toutes les variables explicatives)
alias(modele_log_sel_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r log-sel-max-summary}
summary(modele_log_sel_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode descendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R log-sel-best, results = 'hide'}
modele_log_sel_best <- step(modele_log_sel_max, data = datag, direction = "backward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le maximal (en √¥tant des variables)
```

Meilleur mod√®le (AIC = 40.22)

```{R log-sel-best-summary}
summary(modele_log_sel_best)
tbl_regression(modele_log_sel_best, 
               exponentiate = T,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression logistique multiple le plus performant (AIC = 40.22) pour pr√©dire la <i>Condition</i> avec les variables fortement corr√©l√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(estimate = "OR = Rapports des Chances", std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(include = c(AIC)) # Statistiques du mod√®le
```

### b) R√©gression lin√©aire multiple

#### Mod√®le minimal

Cr√©ation

```{R sel-min, results = 'hide'}
modele_sel_min = lm(datag$Condition ~ 1, data = datag) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r sel-min-summary}
summary(modele_sel_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{R sel-max, results = 'hide'}
modele_sel_max = lm(datag$Condition ~  Haut_visage + Jambes + Pieds + Pas_P2_Cible + EAFF_BES + ContSc_BES, data = datag) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_sel_max) # R√©sum√© du mod√®le
summary(modele_sel_max) # Autre r√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R sel-best, results = 'hide'}
modele_sel_best <- step(modele_sel_min, scope = list(lower = modele_sel_min, upper = modele_sel_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 45.75)

```{R sel-best-summary}
summary(modele_sel_best)
tbl_regression(modele_sel_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 45.75) pour pr√©dire la <i>Condition</i> avec les variables fortement corr√©l√©es et expliquant 30.3% de la variance des donn√©es.</b></center>") %>%# L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-sel-best}
summary.aov(modele_sel_best) # R√©sum√©
```

## 5. <i>Condition</i> et les 5 scores cibl√©s (BES, DDS, arousal)

### a) R√©gression logistique multiple

#### Mod√®le minimal

Cr√©ation

```{r log-tests-min, results = 'hide'}
modele_log_tests_min = glm(datag$Condition ~ 1, data = datag, family = binomial) # Cr√©ation du mod√®le de r√©gression logistique multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r log-tests-min-summary}
summary(modele_log_tests_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

Cr√©ation

```{r log-tests-max, results = 'hide'}
modele_log_tests_max = glm(datag$Condition ~ EAFF_BES + Ecog_BES + Machiavelisme_DDS + Psychopathie_DDS + Excitation_ADCL, data = datag, family = binomial) # Cr√©ation du mod√®le de r√©gression logistique multiple maximal (toutes les variables explicatives)
alias(modele_log_tests_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r log-tests-max-summary}
summary(modele_log_tests_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode descendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R log-tests-best, results = 'hide'}
modele_log_tests_best <- step(modele_log_tests_max, data = datag, direction = "backward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le maximal (en √¥tant des variables)
```

Meilleur mod√®le (AIC = 46.06)

```{R log-tests-best-summary}
summary(modele_log_tests_best)
tbl_regression(modele_log_tests_best, 
               exponentiate = T, # Nom des lignes
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression logistique multiple le plus performant (AIC = 46.06) pour pr√©dire la <i>Condition</i> avec les 5 scores cibl√©s.</b></center>")%>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(estimate = "OR = Rapports des Chances", std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(include = c(AIC)) # Statistiques du mod√®le
```

### b) R√©gression lin√©aire multiple

#### Mod√®le minimal

Cr√©ation

```{R tests-min, results = 'hide'}
modele_tests_min = lm(datag$Condition ~ 1, data = datag) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r tests-min-summary}
summary(modele_tests_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{R tests-max, results = 'hide'}
modele_tests_max = lm(datag$Condition ~ EAFF_BES + Ecog_BES + Machiavelisme_DDS + Psychopathie_DDS + Excitation_ADCL, data = datag) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_tests_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r tests-max-summary}
summary(modele_tests_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R tests-best, results = 'hide'}
modele_tests_best <- step(modele_tests_min, scope = list(lower = modele_tests_min, upper = modele_tests_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 50.31)

```{R tests-best-summary}
summary(modele_tests_best)
tbl_regression(modele_tests_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 50.31) pour pr√©dire la <i>Condition</i> avec les 5 scores cibl√©s et expliquant 14.4% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-tests-best}
summary.aov(modele_tests_best) # R√©sum√©
```

## 6. Scores cibl√©s (BES, DDS, arousal) et indices non-verbaux

Ces scores √©tant des variables qualitatives discr√®tes, on effectue des r√©gressions lin√©aires multiples.

### a) Pr√©paration des donn√©es

```{r data-scores}
datas <- datag[,2:29]
datas <- copy_labels(datas, datag) # Copie des √©tiquettes
```

### b) Score d'empathie affective (BES)

#### Mod√®le minimal

Cr√©ation

```{R eaff-min, results = 'hide'}
modele_eaff_min = lm(datag$EAFF_BES ~ 1, data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r eaff-min-summary}
summary(modele_eaff_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{R eaff-max, results = 'hide'}
modele_eaff_max = lm(datag$EAFF_BES ~ ., data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_eaff_max)  # R√©sum√© du mod√®le
```

R√©sum√©

```{r eaff-max-summary}
summary(modele_eaff_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R eaff-best, results = 'hide'}
modele_eaff_best <- step(modele_eaff_min, scope = list(lower = modele_eaff_min, upper = modele_eaff_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 176.29)

```{R eaff-best-summary}
summary(modele_eaff_best)
tbl_regression(modele_eaff_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 176.29) pour pr√©dire le <i>score d'empathie affective (BES)</i> et expliquant 60.5% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-eaff}
summary.aov(modele_eaff_best) # R√©sum√©
```

### c) Score d'empathie cognitive (BES)

#### Mod√®le minimal

Cr√©ation

```{R ecog-min, results = 'hide'}
modele_ecog_min = lm(datag$Ecog_BES ~ 1, data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r ecog-min-summary}
summary(modele_ecog_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{R ecog-max, results = 'hide'}
modele_ecog_max = lm(datag$Ecog_BES ~ ., data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_ecog_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r ecog-max-summary}
summary(modele_ecog_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R ecog-best, results = 'hide'}
modele_ecog_best <- step(modele_ecog_min, scope = list(lower = modele_ecog_min, upper = modele_ecog_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 185.54)

```{R ecog-best-summary}
summary(modele_ecog_best)
tbl_regression(modele_ecog_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 185.54) pour pr√©dire le <i>score d'empathie cognitive (BES)</i> et expliquant 29.66% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-ecog}
summary.aov(modele_ecog_best) # R√©sum√©
```

### d) Score de machiav√©lisme (DDS)

#### Mod√®le minimal

Cr√©ation

```{R machia-min, results = 'hide'}
modele_machia_min = lm(datag$Machiavelisme_DDS ~ 1, data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r machia-min-summary}
summary(modele_machia_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{R machia-max, results = 'hide'}
modele_machia_max = lm(datag$Machiavelisme_DDS ~ ., data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_machia_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r machia-max-summary}
summary(modele_machia_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R machia-best, results = 'hide'}
modele_machia_best <- step(modele_machia_min, scope = list(lower = modele_machia_min, upper = modele_machia_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 197.7)

```{R machia-best-summary}
summary(modele_machia_best)
tbl_regression(modele_machia_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 197.7) pour pr√©dire le <i>score de machiav√©lisme (DDS)</i> et expliquant 39.9% de la variance des donn√©es.</b></center.7>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-machia}
summary.aov(modele_machia_best) # R√©sum√©
```

### e) Score de psychopathie (DDS)

#### Mod√®le minimal

Cr√©ation

```{R psycho-min, results = 'hide'}
modele_psycho_min = lm(datag$Psychopathie_DDS ~ 1, data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r psycho-min-summary}
summary(modele_psycho_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{R psycho-max, results = 'hide'}
modele_psycho_max = lm(datag$Psychopathie_DDS ~ ., data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_psycho_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r psycho-max-summary}
summary(modele_psycho_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R psycho-best, results = 'hide'}
modele_psycho_best <- step(modele_psycho_min, scope = list(lower = modele_psycho_min, upper = modele_psycho_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 175.72)

```{R psycho-best-summary}
summary(modele_psycho_best)
tbl_regression(modele_psycho_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 175.72) pour pr√©dire le <i>score de psychopathie (DDS)</i> et expliquant 67.6% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-psycho}
summary.aov(modele_psycho_best) # R√©sum√©
```

### f) Narcissisme (DDS)

#### Mod√®le minimal

Cr√©ation

```{R narci-min, results = 'hide'}
modele_narci_min = lm(datag$Narcissisme_DDS ~ 1, data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r narci-min-summary}
summary(modele_narci_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{R narci-max, results = 'hide'}
modele_narci_max = lm(datag$Narcissisme_DDS ~ ., data = datas)  # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_narci_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r narci-max-summary}
summary(modele_narci_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R narci-best, results = 'hide'}
modele_narci_best <- step(modele_narci_min, scope = list(lower = modele_narci_min, upper = modele_narci_max), data = datag, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 192.07)

```{R narci-best-summary}
summary(modele_narci_best)
tbl_regression(modele_narci_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 192.07) pour pr√©dire le <i>narcissisme (DDS)</i> et expliquant 67.47% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-narci}
summary.aov(modele_narci_best) # R√©sum√©
```

### g) Niveau d'arousal (ADCL)

#### Mod√®le minimal

Cr√©ation

```{R arous-min, results = 'hide'}
modele_arous_min = lm(datag$Excitation_ADCL ~ 1, data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple minimal (aucune variable explicative)
```

R√©sum√©

```{r arous-min-summary}
summary(modele_arous_min) # R√©sum√© du mod√®le
```

¬†

#### Mod√®le maximal

```{R arous-max, results = 'hide'}
modele_arous_max = lm(datag$Excitation_ADCL ~ ., data = datas) # Cr√©ation du mod√®le de r√©gression lin√©aire multiple maximal (toutes les variables explicatives)
alias(modele_arous_max) # R√©sum√© du mod√®le
```

R√©sum√©

```{r arous-max-summary}
summary(modele_arous_max) # R√©sum√© du mod√®le
```

¬†

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R arous-best, results = 'hide'}
modele_arous_best <- step(modele_arous_min, scope = list(lower = modele_arous_min, upper = modele_arous_max), data = datag, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
```

Meilleur mod√®le (AIC = 149.9)

```{R arous-best-summary}
summary(modele_arous_best)
tbl_regression(modele_arous_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 149.9) pour pr√©dire le <i>niveau d'arousal (ADCL)</i> et expliquant 37.4% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

Analyse de la Variance du mod√®le

```{r aov-arous}
summary.aov(modele_arous_best) # R√©sum√©
```

## 7. Indices non-verbaux pertinents et scores cibl√©s

Ces scores √©tant des variables qualitatives discr√®tes, on effectue des r√©gressions lin√©aires multiples.

### a) Pr√©paration des donn√©es

```{r data-ind-pert}
#datap <- data[,c('Sexe', 'Condition', 'Bas_visage', 'Haut_visage', 'Bras', 'Mains', 'Jambes', 'Haut_visage2', 'Pas_P2_Cible', 'EAFF_BES', 'Ecog_BES', 'Machiavelisme_DDS', 'Psychopathie_DDS', 'Narcissisme_DDS', 'Excitation_ADCL')] # Conserver les indices pertinents et les 5 scores cibles
datap <- data[,c('Sexe', 'Condition', 'Bas_visage', 'Haut_visage', 'Yeux', 'Bras', 'Mains', 'Jambes', 'Temps_P1_P2', 'Haut_visage2', 'Buste2', 'Pas_P2_Cible', 'EAFF_BES', 'Ecog_BES', 'Machiavelisme_DDS', 'Psychopathie_DDS', 'Narcissisme_DDS', 'Excitation_ADCL')] # Conserver les indices pertinents et les 5 scores cibles
datap <- copy_labels(datap, data) # Copie des √©tiquettes
```

### b) Mouvements du bas du visage √† l'arr√™t 1

#### Recherche du meilleur mod√®le

```{r ind-pert-basvis1-min-max}
modele_basvis1_min = lm(datap$Bas_visage ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_basvis1_max = lm(datap$Bas_visage ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Excitation_ADCL + datap$Narcissisme_DDS, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_basvis1_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R ind-pert-basvis1-best, results = 'hide'}
modele_basvis1_best <- step(modele_basvis1_min, scope = list(lower = modele_basvis1_min, upper = modele_basvis1_max), data = datap, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_basvis1_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 114.55)

```{R basvis1-summary}
tbl_regression(modele_basvis1_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 114.55) pour pr√©dire le <i>nombre de mouvements du bas du visage √† l'arr√™t 1</i> et expliquant 28.29% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

### c) Mouvements du haut du visage √† l'arr√™t 1

#### Recherche du meilleur mod√®le

```{r ind-pert-hautvis1-min-max}
modele_hautvis1_min = lm(datap$Haut_visage ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_hautvis1_max = lm(datap$Haut_visage ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression
summary(modele_hautvis1_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R ind-pert-hautvis1-best, results = 'hide'}
modele_hautvis1_best <- step(modele_hautvis1_min, scope = list(lower = modele_hautvis1_min, upper = modele_hautvis1_max), data = datap, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_hautvis1_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 5.25)

```{R hautvis1-summary}
tbl_regression(modele_hautvis1_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 5.25) pour pr√©dire le <i>nombre de mouvements du haut du visage √† l'arr√™t 1</i> et expliquant 6.8% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

### d) Mouvements des yeux √† l'arr√™t 1

#### Recherche du meilleur mod√®le

```{r ind-pert-yeux1-min-max}
modele_yeux1_min = lm(datap$Yeux ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_yeux1_max = lm(datap$Yeux ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Excitation_ADCL + datap$Narcissisme_DDS, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_yeux1_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R ind-pert-yeux1-best, results = 'hide'}
modele_yeux1_best <- step(modele_yeux1_min, scope = list(lower = modele_yeux1_min, upper = modele_yeux1_max), data = datap, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_yeux1_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 139.38)

```{R yeux1-summary}
tbl_regression(modele_yeux1_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 139.38) pour pr√©dire le <i>nombre de mouvements des yeux √† l'arr√™t 1</i> et expliquant 38.07% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

### e) Mouvements des bras √† l'arr√™t 1

#### Recherche du meilleur mod√®le

```{r ind-pert-bras1-min-max}
modele_bras1_min = lm(datap$Bras ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_bras1_max = lm(datap$Bras ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_bras1_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R ind-pert-bras1-best, results = 'hide'}
modele_bras1_best <- step(modele_bras1_min, scope = list(lower = modele_bras1_min, upper = modele_bras1_max), data = datap, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_bras1_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 55.19)

```{R bras1-summary}
tbl_regression(modele_bras1_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 55.19) pour pr√©dire le <i>nombre de mouvements des bras √† l'arr√™t 1</i> et expliquant 27.78% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

### f) Mouvements des mains √† l'arr√™t 1

#### Recherche du meilleur mod√®le

```{r ind-pert-mains1-min-max}
modele_mains1_min = lm(datap$Mains ~ 1, data = datap)  # Cr√©ation du mod√®le de r√©gression minimal
modele_mains1_max = lm(datap$Mains ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_mains1_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R ind-pert-mains1-best, results = 'hide'}
modele_mains1_best <- step(modele_mains1_min, scope = list(lower = modele_mains1_min, upper = modele_mains1_max), data = datap, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_mains1_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 97.97)

```{R mains1-summary}
tbl_regression(modele_mains1_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 97.97) pour pr√©dire le <i>nombre de mouvements des mains √† l'arr√™t 1</i> et expliquant 14.3% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

### g) Mouvements des jambes √† l'arr√™t 1

#### Recherche du meilleur mod√®le

```{r ind-pert-jambes1-min-max}
modele_jambes1_min = lm(datap$Jambes ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_jambes1_max = lm(datap$Jambes ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_jambes1_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R ind-pert-jambes1-best, results = 'hide'}
modele_jambes1_best <- step(modele_jambes1_min, scope = list(lower = modele_jambes1_min, upper = modele_jambes1_max), data = datap, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_jambes1_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 162.79)

```{R jambes1-summary}
tbl_regression(modele_jambes1_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 162.79) pour pr√©dire le <i>nombre de mouvements des jambes √† l'arr√™t 1</i> et expliquant 39.01% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

### h) Temps entre l'arr√™t 1 et l'arr√™t 2

#### Recherche du meilleur mod√®le

```{r ind-pert-tempsp1p2-min-max}
modele_tempsp1p2_min = lm(datap$Temps_P1_P2 ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_tempsp1p2_max = lm(datap$Temps_P1_P2 ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_tempsp1p2_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R ind-pert-tempsp1p2-best, results = 'hide'}
modele_tempsp1p2_best <- step(modele_tempsp1p2_min, scope = list(lower = modele_tempsp1p2_min, upper = modele_tempsp1p2_max), data = datap, direction = "forward") # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_tempsp1p2_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 69.7)

```{R tempsp1p2-summary}
tbl_regression(modele_tempsp1p2_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 69.7) pour pr√©dire le <i>temps entre l'arr√™t 1 et l'arr√™t 2</i> et expliquant 18.69% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

### i) Mouvements du haut du visage √† l'arr√™t 2

#### Recherche du meilleur mod√®le

```{r ind-pert-hautvis2-min-max}
modele_hautvis2_min = lm(datap$Haut_visage2 ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_hautvis2_max = lm(datap$Haut_visage2 ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_hautvis2_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R ind-pert-hautvis2-best, results = 'hide'}
modele_hautvis2_best <- step(modele_hautvis2_min, scope = list(lower = modele_hautvis2_min, upper = modele_hautvis2_max), data = datap, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_hautvis2_best) # R√©sum√© du mod√®le
```

### j) Mouvements du buste √† l'arr√™t 2

#### Recherche du meilleur mod√®le

```{r ind-pert-buste2-min-max}
modele_buste2_min = lm(datap$Buste2 ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_buste2_max = lm(datap$Buste2 ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_buste2_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R ind-pert-buste2-best, results = 'hide'}
modele_buste2_best <- step(modele_buste2_min, scope = list(lower = modele_buste2_min, upper = modele_buste2_max), data = datap, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_buste2_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 166.56)

```{R buste2-summary}
tbl_regression(modele_buste2_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 166.56) pour pr√©dire le <i>mouvements du buste √† l'arr√™t 2</i> et expliquant 21.09% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```


### k) Nombre de pas entre l'arr√™t 2 et la cible

#### Recherche du meilleur mod√®le

```{r ind-pert-pasp2cible-min-max}
modele_pasp2cible_min = lm(datap$Pas_P2_Cible ~ 1, data = datap) # Cr√©ation du mod√®le de r√©gression minimal
modele_pasp2cible_max = lm(datap$Pas_P2_Cible ~ datap$Sexe + datap$Condition + datap$EAFF_BES + datap$Ecog_BES + datap$Machiavelisme_DDS + datap$Psychopathie_DDS + datap$Narcissisme_DDS + datap$Excitation_ADCL, data = datap) # Cr√©ation du mod√®le de r√©gression maximal
summary(modele_pasp2cible_max) # R√©sum√© du mod√®le
```

#### Meilleur mod√®le

Nous allons utiliser la m√©thode ascendante avec l'AIC.

üí° *Retirer `results='hide'` pour afficher les d√©tails.*

```{R ind-pert-pasp2cible-best, results = 'hide'}
modele_pasp2cible_best <- step(modele_pasp2cible_min, scope = list(lower = modele_pasp2cible_min, upper = modele_pasp2cible_max), data = datap, direction = "forward")  # Recherche du mod√®le minimisant l'AIC en partant du mod√®le minimal (en ajoutant des variables)
summary(modele_pasp2cible_best) # R√©sum√© du mod√®le
```

Meilleur mod√®le (AIC = 96.98)

```{R pasp2cible-summary}
tbl_regression(modele_pasp2cible_best,
               estimate_fun = purrr::partial(style_ratio, digits = 3), # Nombre de d√©cimales des coefficients
               pvalue_fun = purrr::partial(style_sigfig, digits = 4)) %>% # Nombre de d√©cimale des p-valeurs
  modify_caption("<center><b>Mod√®le de r√©gression lin√©aire multiple le plus performant (AIC = 96.98) pour pr√©dire le <i>nombre de pas entre l'arr√™t 2 et la cible</i> et expliquant 8.14% de la variance des donn√©es.</b></center>") %>% # L√©gende
  modify_header(label = "**Variable**", p.value = "**p-valeur**") %>% # Ent√™te
  modify_footnote(std.error = "SE = Erreur Type", ci = "CI = Intervalle de Confiance", abbreviation = TRUE)  %>% # Abbr√©viations
  add_significance_stars(hide_ci = FALSE, 
                         hide_p = FALSE,
                         pattern = "{p.value}{stars}") %>% # Niveau de significativit√©
  add_glance_source_note(label = list(sigma ~ "\U03C3", adj.r.squared ~ "R\xc2\xb2 ajust√©",  r.squared ~ "R\xc2\xb2", p.value ~ "p-valeur"),
                         include = c(adj.r.squared, r.squared,AIC, p.value, sigma)) # Statistiques du mod√®le
```

# V -- Graphiques

## 1. <i>Condition</i> et scores cibles

### a) Score d'empathie affective (BES)

```{r graph-cond-eaff}
ggboxplot(data, x = "Condition", y = "EAFF_BES", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Score d'empathie affective (BES)",
          title = "Score d'empathie affective (BES) selon la condition.")
```

### b) Score d'empathie cognitive (BES)

```{r graph-cond-ecog}
ggboxplot(data, x = "Condition", y = "Ecog_BES", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Score d'empathie cognitive (BES)",
          title = "Score d'empathie cognitive (BES) selon la condition.")
```

### c) Score de machiav√©lisme (DDS)

```{r graph-cond-machia}
ggboxplot(data, x = "Condition", y = "Machiavelisme_DDS", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Score de machiav√©lisme (DDS)",
          title = "Score de machiav√©lisme (DDS) selon la condition.")
```

### d) Score de psychopathie (DDS)

```{r graph-cond-psycho}
ggboxplot(data, x = "Condition", y = "Psychopathie_DDS", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Score de psychopathie (DDS)",
          title = "Score de psychopathie (DDS) selon la condition.")
```

### e) Score de narcissisme (DDS)

```{r graph-cond-narci}
ggboxplot(data, x = "Condition", y = "Narcissisme_DDS", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Score de narcissisme (DDS)",
          title = "Score de narcissisme (DDS) selon la condition.")
```

### f) Niveau d'arousal (ADCL)

```{r graph-cond-arousal}
ggboxplot(data, x = "Condition", y = "Excitation_ADCL", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Niveau d'arousal (ADCL)",
          title = "Niveau d'arousal (ADCL) selon la condition.")
```

## 2. <i>Condition</i> et variables avec une corr√©lation sup√©rieure √† 40%

### a) Jambes √† l'arr√™t 2

```{r graph-cond-jambes2}
ggboxplot(data, x = "Condition", y = "Jambes2", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Nombre de mouvements des jambes",
          title = "Nombre de mouvements des jambes selon la condition.")
```

### b) Score Contagion √âmotionelle (BES)

```{r graph-cond-contsc}
ggboxplot(data, x = "Condition", y = "ContSc_BES", color = "Sexe",
          palette = c("#870A48", "#12711C"),
          ylab = "Score de contagion √©motionnelle (BES)",
          title = "Score de contagion √©motionnelle (BES) selon la condition.")
```
